# **CloudPedagogy AI Capability Framework (2026 Edition)**

*A developmental guide for ethical, strategic, and creative capability across Artificial Intelligence in education, research, and public services*

**Author:** Jonathan Wong, CloudPedagogy  
**Institution/Platform:** CloudPedagogy  
**Version:** 2026 Edition  
**Licence:** CC BY-NC-SA 4.0 – Attribution – NonCommercial – ShareAlike  
**For more information:** cloudpedagogy.com

# Table of Contents

[CloudPedagogy AI Capability Framework (2026 Edition) [1](#cloudpedagogy-ai-capability-framework-2026-edition)](#cloudpedagogy-ai-capability-framework-2026-edition)

[1. Overview of the AI Capability Framework [6](#_t2a7eilrvhl6)](#_t2a7eilrvhl6)

[1.1 Purpose and Scope [6](#purpose-and-scope)](#purpose-and-scope)

[1.2 Framework Structure [6](#framework-structure)](#framework-structure)

[1.3 Supporting Resources [7](#_unyhzn316f0s)](#_unyhzn316f0s)

[1.4 Intended Audience [7](#intended-audience)](#intended-audience)

[1.5 Use Across AI Systems [7](#use-across-ai-systems)](#use-across-ai-systems)

[1.6 What’s New in the 2026 Edition [7](#_459axqqo1rtn)](#_459axqqo1rtn)

[1.7 How to Navigate This Edition [8](#how-to-navigate-this-edition)](#how-to-navigate-this-edition)

[2. Foreword for International Readers [9](#_iaaegh72j63u)](#_iaaegh72j63u)

[3. Quick Start: How to Use This Framework [10](#quick-start-how-to-use-this-framework)](#quick-start-how-to-use-this-framework)

[**For Quick Reflection** [10](#for-quick-reflection)](#for-quick-reflection)

[**For Structured Development** [11](#for-structured-development)](#for-structured-development)

[**For Project or Policy Application** [11](#for-project-or-policy-application)](#for-project-or-policy-application)

[**Suggested Pathway** [11](#suggested-pathway)](#suggested-pathway)

[**Adoption Checklist (Rapid Start)** [12](#_ectvkjpqbv5b)](#_ectvkjpqbv5b)

[**Tips for Effective Use** [12](#tips-for-effective-use)](#tips-for-effective-use)

[**Why This Approach Works** [12](#why-this-approach-works)](#why-this-approach-works)

[4. Introduction and Purpose [13](#_8dubymcxcle6)](#_8dubymcxcle6)

[**4.1 From Competence to Capability** [13](#from-competence-to-capability)](#from-competence-to-capability)

[**4.2 Generative Capability and Ecological Learning** [13](#generative-capability-and-ecological-learning)](#generative-capability-and-ecological-learning)

[**4.3 Capability as Design Practice** [14](#capability-as-design-practice)](#capability-as-design-practice)

[**4.4 From Digital Literacy to Reflective Intelligence** [14](#from-digital-literacy-to-reflective-intelligence)](#from-digital-literacy-to-reflective-intelligence)

[**4.5 Why a Universal AI Capability Framework** [14](#why-a-universal-ai-capability-framework)](#why-a-universal-ai-capability-framework)

[**4.6 A Developmental Structure for Responsible AI** [15](#a-developmental-structure-for-responsible-ai)](#a-developmental-structure-for-responsible-ai)

[**4.7 Integrating with Global and Sectoral Agendas** [15](#integrating-with-global-and-sectoral-agendas)](#integrating-with-global-and-sectoral-agendas)

[**4.8 Invitation to Co-Creation** [16](#_azk3nj3bhyvf)](#_azk3nj3bhyvf)

[**4.9 Concluding Purpose** [16](#concluding-purpose)](#concluding-purpose)

[5. The AI Capability Framework (Core Model) [17](#_1a92ba3p82za)](#_1a92ba3p82za)

[5.1 The Six Domains [17](#the-six-domains)](#the-six-domains)

[**Domain 1 — AI Awareness and Orientation** [17](#domain-1-ai-awareness-and-orientation)](#domain-1-ai-awareness-and-orientation)

[**Domain 2 — Human–AI Co-Agency** [18](#domain-2-humanai-co-agency)](#domain-2-humanai-co-agency)

[**Domain 3 — Applied Practice and Innovation** [18](#domain-3-applied-practice-and-innovation)](#domain-3-applied-practice-and-innovation)

[**Domain 4 — Ethics, Equity and Impact** [19](#_nqugk1nenx9l)](#_nqugk1nenx9l)

[**Domain 5 — Decision-Making and Governance** [19](#domain-5-decision-making-and-governance)](#domain-5-decision-making-and-governance)

[**Domain 6 — Reflection, Learning and Renewal** [20](#_ng4lu84nvk8c)](#_ng4lu84nvk8c)

[5.2 Cross-Domain Interdependence [20](#cross-domain-interdependence)](#cross-domain-interdependence)

[**The Flow of Capability** [20](#the-flow-of-capability)](#the-flow-of-capability)

[**Illustrative Micro-Cases** [21](#illustrative-micro-cases)](#illustrative-micro-cases)

[**The Ecological View** [21](#the-ecological-view)](#the-ecological-view)

[6. Self-Assessment Matrix: Mapping Developmental Capability [22](#_uiq75ydd2xag)](#_uiq75ydd2xag)

[6.1 How to Use the Matrix [22](#how-to-use-the-matrix)](#how-to-use-the-matrix)

[6.2 Capability Progression Matrix [23](#_pr2tioye1p5f)](#_pr2tioye1p5f)

[**Domain 1: AI Awareness and Orientation** [23](#domain-1-ai-awareness-and-orientation-1)](#domain-1-ai-awareness-and-orientation-1)

[**Domain 2: Human–AI Co-Agency** [23](#domain-2-humanai-co-agency-1)](#domain-2-humanai-co-agency-1)

[**Domain 3: Applied Practice and Innovation** [23](#domain-3-applied-practice-and-innovation-1)](#domain-3-applied-practice-and-innovation-1)

[**Domain 4: Ethics, Equity and Impact** [23](#domain-4-ethics-equity-and-impact-1)](#domain-4-ethics-equity-and-impact-1)

[**Domain 5: Decision-Making and Governance** [24](#domain-5-decision-making-and-governance-1)](#domain-5-decision-making-and-governance-1)

[**Domain 6: Reflection, Learning and Renewal** [24](#domain-6-reflection-learning-and-renewal-1)](#domain-6-reflection-learning-and-renewal-1)

[6.3 Developmental Insights [24](#developmental-insights)](#developmental-insights)

[**Interpreting the Matrix** [24](#interpreting-the-matrix)](#interpreting-the-matrix)

[**Developmental Narratives by Domain** [25](#_7r6xnph7zth2)](#_7r6xnph7zth2)

[**Common Developmental Tensions** [25](#common-developmental-tensions)](#common-developmental-tensions)

[**Review and Renewal** [25](#review-and-renewal)](#review-and-renewal)

[7. Reflection Toolkit [26](#_bxq1tqqd78e4)](#_bxq1tqqd78e4)

[7.1 How to Use the Toolkit [26](#how-to-use-the-toolkit)](#how-to-use-the-toolkit)

[**Domain 1 – AI Awareness and Orientation** [27](#_piporjrt2siu)](#_piporjrt2siu)

[**Domain 2 – Human–AI Co-Agency** [27](#domain-2-humanai-co-agency-2)](#domain-2-humanai-co-agency-2)

[**Domain 3 – Applied Practice and Innovation** [28](#_mg8678po5g4z)](#_mg8678po5g4z)

[**Domain 4 – Ethics, Equity and Impact** [28](#domain-4-ethics-equity-and-impact-2)](#domain-4-ethics-equity-and-impact-2)

[**Domain 5 – Decision-Making and Governance** [29](#_m9akz18dlu2r)](#_m9akz18dlu2r)

[**Domain 6 – Reflection, Learning and Renewal** [29](#domain-6-reflection-learning-and-renewal-2)](#domain-6-reflection-learning-and-renewal-2)

[7.2 Integrating Reflection [30](#_x4fo1zjbi3nb)](#_x4fo1zjbi3nb)

[8. AI Interaction and Design Toolkit [31](#_xgk8r03fsgtd)](#_xgk8r03fsgtd)

[8.1 Purpose and Scope [31](#purpose-and-scope-1)](#purpose-and-scope-1)

[8.2 Toolkit Structure (by Domain) [32](#_kal647kp3w97)](#_kal647kp3w97)

[**Domain 1 – AI Awareness and Orientation** [32](#domain-1-ai-awareness-and-orientation-3)](#domain-1-ai-awareness-and-orientation-3)

[**Domain 2 – Human–AI Co-Agency** [32](#domain-2-humanai-co-agency-3)](#domain-2-humanai-co-agency-3)

[**Domain 3 – Applied Practice and Innovation** [33](#domain-3-applied-practice-and-innovation-3)](#domain-3-applied-practice-and-innovation-3)

[**Domain 4 – Ethics, Equity and Impact** [33](#domain-4-ethics-equity-and-impact-3)](#domain-4-ethics-equity-and-impact-3)

[**Domain 5 – Decision-Making and Governance** [34](#_n804fss9sift)](#_n804fss9sift)

[**Domain 6 – Reflection, Learning and Renewal** [34](#domain-6-reflection-learning-and-renewal-3)](#domain-6-reflection-learning-and-renewal-3)

[8.3 Using the Toolkit [35](#_687eww7l06l2)](#_687eww7l06l2)

[9. Scenario-Based Workshop Guides [36](#_t7g12c4ezu78)](#_t7g12c4ezu78)

[Domain 1 – AI Awareness and Orientation (Education) [36](#domain-1-ai-awareness-and-orientation-education)](#domain-1-ai-awareness-and-orientation-education)

[Domain 2 – Human–AI Co-Agency (Healthcare) [37](#domain-2-humanai-co-agency-healthcare)](#domain-2-humanai-co-agency-healthcare)

[Domain 3 – Applied Practice and Innovation (Policy Design) [38](#domain-3-applied-practice-and-innovation-policy-design)](#domain-3-applied-practice-and-innovation-policy-design)

[Domain 4 – Ethics, Equity and Impact (Research Governance) [39](#domain-4-ethics-equity-and-impact-research-governance)](#domain-4-ethics-equity-and-impact-research-governance)

[Domain 5 – Decision-Making and Governance (Institutional Governance) [40](#domain-5-decision-making-and-governance-institutional-governance)](#domain-5-decision-making-and-governance-institutional-governance)

[Domain 6 – Reflection, Learning and Renewal (Organisational Learning) [41](#domain-6-reflection-learning-and-renewal-organisational-learning)](#domain-6-reflection-learning-and-renewal-organisational-learning)

[9.1 Implementation Tips [42](#_icv96taommaa)](#_icv96taommaa)

[10. Applied Examples: The Framework in Action [43](#applied-examples-the-framework-in-action)](#applied-examples-the-framework-in-action)

[10.1 Education – Embedding Responsible AI in a New University Module [43](#_ar7fu4z3pyvd)](#_ar7fu4z3pyvd)

[10.2 Healthcare – Improving Patient Communication [44](#_l5cjqrs5mn30)](#_l5cjqrs5mn30)

[10.3 Public Services – Data-Informed Policy Design [45](#_mvzxdtrtjtn4)](#_mvzxdtrtjtn4)

[**Cross-Case Insights** [46](#_r24x11a2jsae)](#_r24x11a2jsae)

[11. Governance and Ethics Templates [47](#_z9nichsiblz0)](#_z9nichsiblz0)

[11.1 Template A – AI Governance Protocol [47](#_96f8lty7lzs8)](#_96f8lty7lzs8)

[**Sections** [47](#sections)](#sections)

[11.2 Template B – Equity-Focused AI Audit Tool [49](#_700e2g3hzsen)](#_700e2g3hzsen)

[**Sections** [49](#sections-1)](#sections-1)

[**Scoring (optional)** [50](#_wax71rnuz958)](#_wax71rnuz958)

[**Deliverables** [50](#deliverables)](#deliverables)

[11.3 Using These Templates [51](#_pwoa7kly77wh)](#_pwoa7kly77wh)

[**Practical Integration Strategies** [51](#practical-integration-strategies)](#practical-integration-strategies)

[**Cultural Principles for Effective Governance** [51](#cultural-principles-for-effective-governance)](#cultural-principles-for-effective-governance)

[12. Resources and Further Development [52](#_hy736etu0u7y)](#_hy736etu0u7y)

[12.1 In Development [52](#in-development)](#in-development)

[12.2 Invitation to Collaborate [53](#invitation-to-collaborate)](#invitation-to-collaborate)

[12.3 Integration within the CloudPedagogy Platform [54](#_g4hsapez5up8)](#_g4hsapez5up8)

[12.4 Attribution and Licensing [54](#attribution-and-licensing)](#attribution-and-licensing)

[12.5 Closing Note [55](#_wi3noiiky6au)](#_wi3noiiky6au)

[12.6 Measuring Impact (Suggested Indicators) [55](#measuring-impact-suggested-indicators)](#measuring-impact-suggested-indicators)

[12.7 How to Cite [56](#how-to-cite)](#how-to-cite)

[13. Glossary [57](#_z0adzw4ovn23)](#_z0adzw4ovn23)

<span id="_t2a7eilrvhl6" class="anchor"></span>**  **

# **1. Overview of the AI Capability Framework**

## **1.1 Purpose and Scope**

The CloudPedagogy **AI Capability Framework (AICF)** is a developmental guide for building ethical, strategic, and creative capability in the design and use of Artificial Intelligence across education, research, healthcare, policy, and public-service contexts. It offers a structured, values-led approach to integrating AI responsibly—helping individuals, teams, and institutions move beyond tool adoption toward reflective, equitable, and innovative practice.

The AICF is **technology-neutral** and **future-proof**. It applies across generative, predictive, agentic, symbolic, multimodal, hybrid, and emerging systems, focusing on enduring human and organisational capabilities rather than on specific platforms or features.

## **1.2 Framework Structure**

The framework is organised around **six interdependent domains** that together define the breadth of AI capability:

- **AI Awareness and Orientation**

- **Human–AI Co-Agency**

- **Applied Practice and Innovation**

- **Ethics, Equity and Impact**

- **Decision-Making and Governance**

- **Reflection, Learning and Renewal  **

Each domain includes **guiding questions**, a **capability purpose**, **ecological anchors**, **design-thinking modes**, **capability shifts**, and **values-in-practice**. Together they form a coherent **capability ecology** for developing responsible, adaptive, and creative AI practice at individual and organisational levels.

<span id="_unyhzn316f0s" class="anchor"></span>**  **

## **1.3 Supporting Resources**

To operationalise the six domains, the framework provides:

- **Self-Assessment Matrix** — map capability growth across domains and over time.

- **Reflection Toolkit** — prompts for structured dialogue, ethical reasoning, and review.

- **AI Interaction & Design Toolkit** — intentional, auditable, values-aligned engagement with AI.

- **Scenario-Based Workshop Guides** — ready-to-run activities translating concepts into practice.

- **Governance & Ethics Templates** — artefacts that embed transparency and accountability.

- **Applied Examples** — cross-sector cases that demonstrate implementation and outcomes.

## **1.4 Intended Audience**

- **Educators and Academic Developers** — AI-aware curricula, assessment, and learning design.

- **Healthcare and Public-Health Professionals** — clinical reasoning, analytics, and communication.

- **Policy and Governance Leads** — institutional and sectoral oversight, assurance, and risk.

- **Service Designers and Managers** — operational optimisation and citizen-facing services.

- **Researchers and Project Leads** — AI-enabled studies with ethical foresight and auditability.

## **1.5 Use Across AI Systems**

The AICF applies to **all forms of AI**. It centres on **human judgment, contextual knowledge, and collective governance**—capabilities that remain essential as AI architectures, interfaces, and capacities evolve. This ensures the framework can guide practice through current and future paradigms, including autonomous agents and novel computing substrates.

<span id="_459axqqo1rtn" class="anchor"></span>**  **

## **1.6 What’s New in the 2026 Edition**

This edition **expands and elevates** the original Generative AI Capability Framework (GCF) while preserving its strengths:

- **From tool literacy to systemic capability** — shifts focus from “using GenAI well” to **designing, evaluating, and governing AI systems** as part of organisational decision-making.

- **Universal six-domain model** — the domains now **generalise across all AI types**, not only generative.

- **Stronger governance and ethics layer** — practical **protocols, audit tools, and oversight artefacts** that bridge pedagogy and policy.

- **Ecological learning + design thinking** — capability is framed as **relational, developmental, and iterative** (Orient → Assess → Apply → Reflect → Iterate).

- **Cross-sector applicability** — language and examples span **education, research, health, policy, and public services**, with clear routes to localisation and alignment with national and international guidance.

- **Sustainable, evolutionary design** — the framework is a **living system**: stable in core concepts, extensible through updates and sector contributions.

## **1.7 How to Navigate This Edition**

- **Skim the domain summaries** to orient quickly, then choose one or two domains to apply immediately.

- **Run the Self-Assessment Matrix** with a representative group and prioritise growth areas.

- **Adopt the Governance Protocol and Equity Audit** early in project or policy design.

- **Use the AI Interaction & Design Toolkit** to structure intentional, auditable workflows.

- **Close the loop** with the Reflection Toolkit and schedule a 90-day review to track development.

**Rapid Start (Checklist):**

1.  Nominate a cross-functional sponsor

2.  Run the Matrix

3.  Choose two priority domains

4.  Pilot one scenario

5.  Create governance artefacts (AI Use Statement + decision/oversight log)

6.  Review at day 90; iterate

<span id="_iaaegh72j63u" class="anchor"></span>

# **2. Foreword for International Readers**

The CloudPedagogy **AI Capability Framework (2026 Edition)** is written for a world in motion. While its early iterations emerged from higher education and public-service practice in the UK, the principles it advances—**ecological learning**, **design thinking**, **ethical foresight**, and **inclusive innovation**—speak to challenges and opportunities shared across countries, sectors, and cultures. The framework recognises that AI now functions as a *decision layer* in our institutions. It therefore centres human judgement, social values, and organisational learning—not transient tools.

**From competencies to capability.** Many excellent models map digital competencies and AI literacies. This framework builds on that foundation and moves further: from *what people can do with tools* to *how people and organisations think, decide, and govern* in AI-mediated environments. Capability here means adaptive expertise—**the capacity to inquire, design, evaluate, and course-correct** under conditions of uncertainty and change.

**Technology-neutral and future-proof.** The 2026 edition generalises beyond any single AI paradigm. It applies to **generative, predictive, agentic, symbolic, multimodal, and hybrid systems**, and remains relevant as architectures and interfaces evolve. By focusing on enduring human, ethical, and governance capacities, the framework provides stability amid rapid technical change.

**Cross-sector by design.** Although many examples originate in education and research, the six-domain model travels well. It has been written to support **healthcare**, **public administration**, **NGOs and civil society**, and **policy** contexts, where questions of equity, accountability, and public value are acute. You will find scenarios and templates that are readily adapted to clinical reasoning, citizen-facing services, research integrity, and institutional governance.

**Local adaptation encouraged.** We anticipate and welcome **translation, contextualisation, and alignment** with national policies and sector guidance. The language of capability can and should be tailored to local legal frameworks, cultural norms, and professional vocabularies. We provide technology-neutral tools—self-assessment, reflection prompts, interaction design patterns, and governance artefacts—that you can re-express in your own terms while retaining conceptual integrity.

**Bridging pedagogy and policy.** A distinctive aim of this framework is to close the gap between classroom practice and board-level decision-making. Educators will find practical guidance for curriculum and assessment; leaders and oversight bodies will find **protocols, audit tools, and decision logs** that render AI use **transparent, explainable, and contestable**. This dual focus enables consistent practice from pilot to policy.

**Equity and participation as first principles.** AI systems can encode and amplify historical inequities. The framework therefore treats **ethics, equity, and impact** not as add-ons but as design constraints from the outset. Templates encourage participatory approaches, inclusion of impacted communities, and clear escalation pathways when risks are identified. We invite readers to use these tools to strengthen **public trust** and **institutional legitimacy**.

**A living capability ecology.** Finally, this work is offered as part of a shared endeavour. Capability grows through **dialogue, evidence, and iteration**. We invite institutions, networks, and communities of practice to contribute case studies, translate tools, and propose enhancements. Where you improve or localise the artefacts, please share them back so that others may benefit.

If you are reading this in a university, a hospital, a research institute, a government department, or a civil-society organisation, our hope is the same: that this framework helps you build **reflective intelligence**—the human capacity to question, design, and govern AI **with integrity, equity, and care**.

# **3. Quick Start: How to Use This Framework**

The **CloudPedagogy AI Capability Framework** is intentionally flexible. It can be used by individuals, teams, or whole organisations to **explore, apply, and reflect on AI capability** in ways that match local culture, capacity, and priorities. The framework is not a checklist of skills but a developmental guide that supports growth through practice and dialogue.

You can engage with it at three complementary levels: **reflection**, **development**, and **application**.

### **For Quick Reflection**

- **Select a domain.** Skim the six domains and choose the one most relevant to your current project or question.

- **Reflect in context.** Use the **Reflection Toolkit** prompts to guide discussion, journaling, or peer review.

- **Surface assumptions.** Consider what the exercise reveals about how your team defines intelligence, value, or fairness.

- **Document insights.** Capture observations in a shared reflection log or portfolio—small reflections accumulate into organisational learning.

*Purpose:* To build awareness and a shared vocabulary before moving to structured development.

### **For Structured Development**

- **Map current capability.** Use the **Self-Assessment Matrix** to gauge where you and your team sit within each domain.

- **Identify priorities.** Select one or two domains for targeted growth rather than attempting all at once.

- **Design activities.** Draw on the **Scenario-Based Workshop Guides** to run collaborative sessions or CPD workshops.

- **Track progress.** Revisit the matrix periodically—capability evolves unevenly, and movement between levels is expected.

*Purpose:* To embed AI capability into professional development plans, leadership reviews, and cross-functional initiatives.

### **For Project or Policy Application**

- **Start with boundaries.** Use the **Ethics, Equity and Impact** and **Decision-Making and Governance** domains first to define oversight and transparency.

- **Build governance artefacts.** Apply the **Governance and Ethics Templates** to clarify roles, risks, and review points.

- **Design intentional interactions.** Use the **AI Interaction and Design Toolkit** to make engagement auditable and aligned with organisational values.

- **Close the loop.** Schedule structured reflection sessions to capture lessons and adjust workflows.

*Purpose:* To ensure that AI adoption strengthens institutional integrity and public trust while improving effectiveness.

### **Suggested Pathway**

1.  **Orient →** Read the domain summaries for an overview.

2.  **Assess →** Use the matrix to map strengths and gaps.

3.  **Apply →** Choose one or two domains for focused practice.

4.  **Reflect →** Capture learning using the Reflection Toolkit.

5.  **Iterate →** Revisit after 3–6 months to track development and renew commitments.

*The cycle embodies the framework’s ecological logic—capability grows through continuous iteration rather than linear completion.*

> <span id="_ectvkjpqbv5b" class="anchor"></span>
>
> **Adoption Checklist (Rapid Start)**

1.  Nominate a **cross-functional sponsor** or champion.

2.  Run the **Self-Assessment Matrix** with a representative group.

3.  Select **two priority domains** linked to live projects.

4.  Pilot **one scenario** from the Workshop Guides.

5.  Create **governance artefacts** (AI Use Statement + decision/oversight log).

6.  Schedule a **90-day review** using the Reflection Toolkit to capture impact and next steps.

### **Tips for Effective Use**

- **Start small.** Apply one domain or one tool to an active initiative before scaling up.

- **Adapt freely.** Translate examples, prompts, and terminology to your sector or language; capability is contextual.

- **Collaborate.** Capability develops through shared dialogue across roles and disciplines.

- **Keep visible.** Display the six-domain map in digital or physical team spaces to reinforce a common frame of reference.

- **Revisit often.** Treat capability as a continuous organisational learning process, not a one-off compliance exercise.

### **Why This Approach Works**

This structured yet flexible method reflects the framework’s core philosophy: **AI capability is developmental, relational, and renewable.** By cycling through orientation, assessment, application, reflection, and iteration, institutions cultivate *reflective intelligence*—the ability to govern and innovate with AI responsibly, regardless of how technologies evolve.

<span id="_8dubymcxcle6" class="anchor"></span>**  **

# **4. Introduction and Purpose**

Artificial Intelligence is reshaping how knowledge is created, interpreted, and acted upon. It now influences not only what we know, but *how* we know—how evidence is generated, decisions are justified, and futures are imagined. Across education, research, health, policy, and public service, AI offers extraordinary opportunities for innovation, insight, and collaboration. Yet it also exposes new pedagogical, ethical, and societal tensions: questions of authorship, agency, accountability, and trust.

The **CloudPedagogy AI Capability Framework (2026 Edition)** helps organisations engage with these transformations **responsibly, strategically, and creatively**. It defines AI capability not as technical proficiency but as an evolving relationship between **human judgment, machine reasoning, and institutional values**.

### **4.1 From Competence to Capability**

Traditional frameworks often describe *competence*—the ability to perform defined tasks to a fixed standard. Capability, by contrast, is **adaptive expertise**: the capacity to learn, re-design, and make sound decisions in unfamiliar conditions.  
In rapidly changing AI ecosystems, competence alone is insufficient. Models and platforms evolve faster than curricula, governance, or regulation. The crucial question therefore shifts from *“Can we use this tool?”* to *“How do we sustain ethical and reflective practice when the tools change?”*

The Framework positions capability as **context-sensitive reasoning under uncertainty**. It helps individuals and institutions build the judgement to decide when, why, and how to engage AI—not simply how to operate it.

### **4.2 Generative Capability and Ecological Learning**

At its heart lies the principle of **ecological learning**: knowledge is relational, distributed, and continually renewed. Human–AI collaboration functions within an ecology of data, infrastructure, people, and values. Every system we design modifies that environment, influencing future choices and capabilities.

This ecological view reframes AI as a participant in the learning system rather than an external tool. It invites practitioners to ask: *What feedback loops connect our actions, algorithms, and outcomes?* and *How can these loops reinforce equity, transparency, and creativity rather than narrow optimisation?*

The Framework therefore promotes **generative capability**—the ability to create new knowledge responsibly through interplay between human and machine intelligence.

### **4.3 Capability as Design Practice**

Capability becomes tangible through **design thinking**: empathise → define → ideate → prototype → test → reflect.  
Each domain of the Framework aligns with one of these design modes, encouraging users to prototype ideas, evaluate consequences, and iterate based on reflection.  
The **Orient → Assess → Apply → Reflect → Iterate** cycle within CloudPedagogy mirrors this process, turning abstract principles into continuous improvement routines.

By adopting a design mindset, organisations can move beyond compliance toward **co-creation and foresight**—seeing AI not only as a technical challenge but as a creative medium for redesigning systems and relationships.

### **4.4 From Digital Literacy to Reflective Intelligence**

The Framework builds upon respected digital-capability models (Jisc Digital Capabilities, DigComp, EDUCAUSE) yet moves decisively beyond them. Where those frameworks focus on *digital literacy*—knowing how to use digital tools—CloudPedagogy emphasises **reflective intelligence**:

- understanding how AI systems represent the world,

- questioning whose perspectives are encoded or omitted, and

- designing interventions that restore balance and accountability.

Reflective intelligence is both cognitive and ethical. It integrates critical thinking, empathy, and foresight so that users can interpret AI outputs, challenge bias, and align system behaviour with human purpose.

### **4.5 Why a Universal AI Capability Framework**

The 2026 Edition is deliberately **technology-neutral** and **future-proof**. It spans generative, predictive, agentic, symbolic, multimodal, and emerging forms of AI.  
This universality matters because institutions require stability amid continuous technological flux. The Framework abstracts to enduring human and organisational capabilities—**awareness, co-agency, innovation, ethics, governance, and reflection**—which remain relevant whether working with current large-language models or future quantum-enhanced agents.

For CloudPedagogy, this universality creates a sustainable anchor for professional learning, consultancy, and policy alignment. Each course, toolkit, and scenario within the CloudPedagogy ecosystem maps back to these six domains, ensuring conceptual consistency across offerings.

### **4.6 A Developmental Structure for Responsible AI**

The Framework provides a developmental architecture to:

1.  **Build critical understanding** of how AI systems perceive, reason, and decide—and the epistemic assumptions they embody.

2.  **Design purposeful human–AI collaboration** that preserves human judgement while leveraging machine capability.

3.  **Foster creative and inclusive innovation** through safe-to-fail experimentation and ethical prototyping.

4.  **Embed ethics, equity, and foresight** into everyday practice rather than as retrospective checks.

5.  **Develop transparent and participatory governance** through shared accountability and explainability.

6.  **Create cultures of reflection and renewal** that convert learning into ongoing improvement.

Together these outcomes cultivate **resilient capability ecosystems**—organisations that learn with, from, and about AI over time.

### **4.7 Integrating with Global and Sectoral Agendas**

The Framework aligns with international efforts to promote trustworthy and human-centred AI, including the **OECD AI Principles**, the **UNESCO Recommendation on the Ethics of AI**, and the **EU AI Act**. It complements national digital-skills strategies by addressing the organisational and ethical dimensions that those strategies often leave implicit.

By situating capability within broader sustainability and governance agendas—such as the **UN Sustainable Development Goals (SDGs)**—the Framework connects AI practice to societal wellbeing and planetary stewardship.

<span id="_azk3nj3bhyvf" class="anchor"></span>**  **

### **4.8 Invitation to Co-Creation**

The CloudPedagogy AI Capability Framework is intentionally open and collaborative. Users are invited to adapt its language, test its tools, and share insights from implementation. Each iteration enriches the collective intelligence of the community that sustains it.

Capability, like ecology, thrives on diversity and feedback. By contributing case studies, translations, and refinements, practitioners help ensure the Framework remains responsive to emerging technologies and cultural contexts.

### **4.9 Concluding Purpose**

Ultimately, this Framework is not about mastering AI—it is about **mastering the conditions under which AI and humanity learn together**.  
It equips individuals and institutions to approach intelligent systems with curiosity, rigour, and care; to design environments where innovation serves justice; and to treat reflection not as an afterthought but as the heartbeat of ethical progress.

<span id="_1a92ba3p82za" class="anchor"></span>**  **

# **5. The AI Capability Framework (Core Model)**

At the heart of the CloudPedagogy AI Capability Framework lies a **six-domain model** that captures the multidimensional and interdependent nature of capability in the age of intelligent systems.  
Each domain represents a distinct area of practice, but none stands alone: capability develops through the movement **between** domains, not merely within them. The model recognises that learning with AI is an **ecological process**—a continuous cycle of awareness, design, experimentation, governance, and renewal.

Each domain is expressed through a consistent structure:

- **Guiding Question** – the key inquiry anchoring practice.

- **Capability Purpose** – what development in this area seeks to achieve.

- **Ecological Anchor** – the systems, relationships, or values that ground the work.

- **Design-Thinking Mode** – the creative mode most associated with that domain.

- **Capability Shifts** – the developmental movements that mark progression.

- **Values-in-Practice** – dispositions and principles that sustain ethical growth.

Together, these components provide a language for reflection, planning, and evaluation across sectors.

## **5.1 The Six Domains**

### **Domain 1 — AI Awareness and Orientation**

**Guiding Question:** What do we understand about AI and its assumptions?  
**Capability Purpose:** Cultivate critical literacy about how AI systems perceive, reason, and decide—and the social, technical, and epistemic assumptions they carry.  
**Ecological Anchor:** Knowledge systems, data provenance, algorithmic transparency.  
**Design-Thinking Mode:** *Empathise* – understand systems, users, and contexts before design.  
**Capability Shifts:** From passive consumption to critical engagement; from tool neutrality to socio-technical literacy.  
**Values-in-Practice:** Curiosity, transparency, intellectual humility.

Awareness begins the capability journey. It requires curiosity about how models learn, where data come from, and whose perspectives shape them. Awareness is not mere familiarity; it is **epistemic literacy**—the ability to interrogate assumptions and recognise how AI constructs meaning.

### **Domain 2 — Human–AI Co-Agency**

**Guiding Question:** How do we design meaningful partnerships between humans and AI systems?  
**Capability Purpose:** Enable thoughtful distribution of agency, ensuring human judgement and context remain central while leveraging machine capabilities.  
**Ecological Anchor:** Relational agency, affordances, role clarity.  
**Design-Thinking Mode:** *Define* – articulate purpose, boundaries, and responsibilities.  
**Capability Shifts:** From automation-as-default to purposeful collaboration; from indiscriminate use to intentional delegation.  
**Values-in-Practice:** Intentionality, clarity, reciprocity.

Co-agency transforms AI from a background utility into a partner in reasoning. It demands clarity of purpose and **documented accountability**—who interprets, who validates, who decides. Mature co-agency embeds explainability and ethical review as part of the workflow, not as an afterthought.

### **Domain 3 — Applied Practice and Innovation**

**Guiding Question:** How do we experiment, adapt, and create with AI responsibly?  
**Capability Purpose:** Foster creative and contextually sensitive use of AI for prototyping, problem-solving, and knowledge generation.  
**Ecological Anchor:** Systems innovation, cultural adaptation.  
**Design-Thinking Mode:** *Ideate* – generate and test diverse possibilities.  
**Capability Shifts:** From efficiency to inquiry; from risk aversion to ethical experimentation.  
**Values-in-Practice:** Inclusion, creative confidence, safe-to-fail learning.

Innovation here is **reflective experimentation**—testing ideas while anticipating impact. Teams cultivate “safe-to-fail” spaces where creativity and caution coexist, allowing AI to serve as a catalyst for discovery rather than a source of unchecked novelty.

<span id="_nqugk1nenx9l" class="anchor"></span>**  **

### **Domain 4 — Ethics, Equity and Impact**

**Guiding Question:** How do we ensure that AI use is fair, inclusive, and anticipatory?  
**Capability Purpose:** Identify and address structural inequalities, risks, and ethical dilemmas arising from AI design and deployment.  
**Ecological Anchor:** Justice, bias, power, sustainability.  
**Design-Thinking Mode:** *Reframe* – see problems through multiple ethical and social lenses.  
**Capability Shifts:** From ethics-as-compliance to ethics-as-design; from reactive mitigation to proactive foresight.  
**Values-in-Practice:** Accountability, equity, stewardship.

Ethical capability is anticipatory: it looks forward to potential consequences before harm occurs. It integrates **equity audits**, participatory design, and continuous impact assessment so that inclusivity becomes structural rather than symbolic.

### **Domain 5 — Decision-Making and Governance**

**Guiding Question:** How is AI reshaping organisational intelligence and authority?  
**Capability Purpose:** Develop transparent, accountable, and participatory mechanisms for AI-influenced decision-making and oversight.  
**Ecological Anchor:** Institutional trust, power distribution, public value.  
**Design-Thinking Mode:** *Prototype / Test* – build and validate governance mechanisms through iterative use.  
**Capability Shifts:** From opaque automation to explainable augmentation; from centralised control to shared governance.  
**Values-in-Practice:** Transparency, deliberation, fairness.

Governance capability ensures that innovation remains aligned with institutional mission and societal good. It transforms abstract ethics into **operational governance artefacts**—policies, oversight logs, and review cycles that keep AI accountable to human purpose.

<span id="_ng4lu84nvk8c" class="anchor"></span>**  **

### **Domain 6 — Reflection, Learning and Renewal**

**Guiding Question:** How do we learn from, iterate, and course-correct our AI use?  
**Capability Purpose:** Embed feedback loops and collective learning into AI-enabled work, sustaining ethical practice over time.  
**Ecological Anchor:** Learning ecosystems, adaptive culture.  
**Design-Thinking Mode:** *Reflect / Iterate* – integrate evidence and insight into continual improvement.  
**Capability Shifts:** From one-off deployment to continuous improvement; from individual learning to organisational renewal.  
**Values-in-Practice:** Humility, responsiveness, care.

Reflection closes and reopens the capability cycle. It turns outcomes into learning, and learning into improved design. Without structured reflection, awareness stagnates; with it, capability becomes self-renewing.

## **5.2 Cross-Domain Interdependence**

The six domains function as an **interconnected capability ecology**, not a linear sequence. Growth in one stimulates development in others. Each transition between domains represents a dynamic movement of learning, design, and accountability.

### **The Flow of Capability**

1.  **Awareness → Co-Agency:** Critical literacy about AI systems enables purposeful collaboration; people who understand how systems reason can assign responsibility wisely.

2.  **Co-Agency → Innovation:** Clear role boundaries create psychological safety, allowing teams to experiment ethically and imaginatively.

3.  **Innovation → Ethics:** As prototypes emerge, ethical reflection reframes ambition within fairness and sustainability constraints.

4.  **Ethics → Governance:** Ethical insights inform rules, oversight, and audit mechanisms that institutionalise responsibility.

5.  **Governance → Reflection:** Accountability processes generate feedback and evidence for organisational learning.

6.  **Reflection → Awareness:** Insights from review renew understanding of AI’s assumptions, restarting the cycle with deeper literacy.

This continuous circulation keeps capability alive and adaptive. The model’s recursive design ensures that new knowledge, once reflected upon, becomes the foundation for the next iteration of awareness and co-agency.

### **Illustrative Micro-Cases**

- *In curriculum design,* awareness of model bias (Domain 1) informed equitable data curation (Domain 4), producing explainable assessment policies (Domain 5).

- *In healthcare analytics,* co-agency between clinicians and AI triage systems (Domain 2) drove innovations in multilingual communication (Domain 3), supported by ongoing reflective audit (Domain 6).

- *In municipal policy,* iterative governance reviews (Domain 5) generated new awareness (Domain 1) about algorithmic exclusion, prompting cross-departmental learning (Domain 6).

### **The Ecological View**

Seen as a whole, the six domains form a **capability ecosystem**. Awareness grounds the system; co-agency gives it structure; innovation provides energy; ethics and governance stabilise it; reflection renews it.  
Because AI contexts evolve continuously, capability must do the same. The Framework therefore represents a **living architecture**—adaptive, participatory, and self-correcting—through which individuals and organisations can navigate complexity with integrity and imagination.

<span id="_uiq75ydd2xag" class="anchor"></span>**  **

# **6. Self-Assessment Matrix: Mapping Developmental Capability**

The **Self-Assessment Matrix** supports individuals, teams, and organisations in exploring their evolving relationship with AI. It aligns directly with the Framework’s six domains, offering a **shared developmental language** rather than a compliance checklist. Its purpose is not to measure competence in a fixed sense, but to prompt reflection, dialogue, and iterative learning across diverse contexts.

Capability grows through **movement**, not grading — by noticing patterns, setting intentions, and returning to reflect on progress. Users are encouraged to treat the matrix as a **mirror**, not a scoreboard: it reflects how you are learning with and through AI within your own organisational ecology.

## **6.1 How to Use the Matrix**

Use the matrix to:

- **Guide professional dialogue** – support one-to-one coaching, mentoring, and appraisal conversations that include ethical and strategic dimensions of AI use.

- **Inform CPD and training design** – shape workshops or courses tied to AI adoption, literacy, and governance.

- **Facilitate team reflection** – surface collective strengths, gaps, and shared language across disciplines.

- **Support institutional planning** – use aggregated insights to inform strategy for AI governance, curriculum redesign, or digital transformation.

- **Track developmental progress** – compare perspectives over time or across projects to reveal how capability is evolving.

Aim for **capability progression**, not performance scoring. Growth may occur unevenly across domains depending on context, resources, and leadership support. Such asymmetry is expected: capability ecologies are rarely uniform.

<span id="_pr2tioye1p5f" class="anchor"></span>**  **

## **6.2 Capability Progression Matrix**

Each domain can be viewed as a developmental trajectory from **Emerging → Developing → Proficient → Advanced**, representing shifts in mindset, practice, and organisational integration.

### **Domain 1: AI Awareness and Orientation**

- **Emerging:** Surface-level awareness; influenced by hype and marketing narratives.

- **Developing:** Can explain basic principles, benefits, and risks.

- **Proficient:** Understands data, bias, and interpretability; questions assumptions and provenance.

- **Advanced:** Demonstrates deep critical literacy; mentors others; fosters transparency and epistemic humility.

### **Domain 2: Human–AI Co-Agency**

- **Emerging:** Uses AI with limited reflection on purpose or human role.

- **Developing:** Differentiates tasks for humans and AI; begins intentional workflow design.

- **Proficient:** Establishes clear co-agency structures; adapts collaboration to context and values.

- **Advanced:** Leads purposeful partnerships; mentors peers; embeds role clarity, authorship, and accountability.

### **Domain 3: Applied Practice and Innovation**

- **Emerging:** Sporadic, efficiency-driven use; limited creativity or reflection.

- **Developing:** Experiments within familiar contexts; learns from trial and error.

- **Proficient:** Integrates AI into creative problem-solving with ethical awareness.

- **Advanced:** Champions inclusive, values-led innovation; builds safe-to-fail cultures; shares learning organisation-wide.

### **Domain 4: Ethics, Equity and Impact**

- **Emerging:** Unaware of structural bias or ethical implications.

- **Developing:** Identifies risks and fairness concerns; references emerging frameworks.

- **Proficient:** Embeds equity and foresight into design and decision-making processes.

- **Advanced:** Shapes ethical governance; advocates systemic fairness; models anticipatory and justice-oriented ethics.

### **Domain 5: Decision-Making and Governance**

- **Emerging:** Accepts AI outputs without review; lacks transparency.

- **Developing:** Recognises AI influence on decisions; begins designing oversight.

- **Proficient:** Implements explainable and participatory decision workflows.

- **Advanced:** Leads accountable governance; integrates oversight into cross-sector or multi-disciplinary systems.

### **Domain 6: Reflection, Learning and Renewal**

- **Emerging:** Engages once or intermittently; limited documentation of reflection.

- **Developing:** Discusses outcomes and lessons learned; open to feedback.

- **Proficient:** Embeds structured feedback loops; encourages team-based reflection.

- **Advanced:** Cultivates organisational learning ecosystems; updates policy and systems responsively.

## **6.3 Developmental Insights**

Capability is **dynamic and non-linear**. Teams may display different levels across domains simultaneously. A university may be *Proficient* in innovation yet only *Developing* in governance; a health organisation may excel in ethics but remain *Emerging* in reflective learning. The goal is not symmetry but **systemic coherence**—each domain reinforcing the others over time.

### **Interpreting the Matrix**

- Use the descriptors as **conversation starters** rather than rigid benchmarks. Ask *“What evidence supports our current position?”* and *“What would progress look like in our context?”*

- Discuss how development in one domain could strengthen another. For example, improving Co-Agency (Domain 2) often accelerates governance maturity (Domain 5).

- Capture insights in an action plan or reflective journal to inform the next iteration of your Orient → Assess → Apply → Reflect → Iterate cycle.

<span id="_7r6xnph7zth2" class="anchor"></span>**  **

### **Developmental Narratives by Domain**

- **Awareness** grows through curiosity and informed critique—reading diverse sources, discussing bias, and facilitating literacy workshops.

- **Co-Agency** develops through documentation of responsibilities, joint experimentation, and mentoring on shared decision processes.

- **Innovation** matures via iterative pilots, open sharing of both successes and failures, and cross-sector collaboration.

- **Ethics** advances through consistent use of foresight tools, equity audits, and transparent handling of dilemmas.

- **Governance** deepens when oversight structures become participatory and data for accountability are publicly accessible.

- **Reflection** strengthens when review practices are embedded into everyday operations and linked to visible changes.

### **Common Developmental Tensions**

Capability building surfaces healthy tensions—speed versus depth, innovation versus caution, autonomy versus oversight. Rather than framing these as contradictions, the Framework treats them as **learning thresholds**: moments where dialogue and reflection lead to growth.

Each tension signals the need for recalibration rather than retreat. Balancing creativity with accountability, or openness with privacy, is itself a measure of capability maturity.

### **Review and Renewal**

It is recommended that the matrix be revisited every **6–12 months**. Combine it with data from reflection logs, governance audits, and workshop outputs. Discuss findings collaboratively and publish aggregated results where appropriate. Transparency in capability review reinforces trust and shared accountability.

Over time, these cycles transform the matrix from a diagnostic tool into a **living developmental ledger**—a record of institutional learning, ethical commitment, and adaptive growth.

<span id="_bxq1tqqd78e4" class="anchor"></span>**  **

# **7. Reflection Toolkit**

The **Reflection Toolkit** deepens ethical reasoning, critical inquiry, and collaborative learning across the six domains. It provides structured prompts for dialogue, journaling, and team review—helping practitioners surface assumptions, question impacts, and refine their approach to AI design, deployment, and oversight.

Reflection is not an optional add-on; it is a **core capability** that sustains **resilience, trust, and adaptive intelligence**. Through reflective practice, individuals and organisations transform activity into learning, and learning into renewal.

## **7.1 How to Use the Toolkit**

The prompts are designed to be flexible and sector-neutral. They may be used in workshops, leadership meetings, curriculum reviews, research supervision, or service design.

**Suggested applications**

- **Workshops and meetings:** Integrate 10–15 minute reflection cycles at the end of agenda items.

- **Learning portfolios or journals:** Select one domain per week to document insights, dilemmas, and next steps.

- **Leadership reviews:** Pair with the **Self-Assessment Matrix** to connect reflection with strategic capability planning.

- **Scenario-based learning:** Use prompts to debrief after completing one of the **Scenario Guides**.

- **Cultural adaptation:** Adjust wording to local norms and professional language while retaining intent.

Each question set below may be used independently or as part of an extended reflective cycle following the Framework’s five-step process: **Orient → Assess → Apply → Reflect → Iterate**.

<span id="_piporjrt2siu" class="anchor"></span>**  **

### **Domain 1 – AI Awareness and Orientation**

**Team reflection**

- What assumptions about intelligence or knowledge underpin the tools we use?

- How confident are we in spotting inaccuracy or bias?

- What perspectives or data sources are missing?

**Individual reflection**

- Which sources shape my understanding of AI and its limitations?

- How can I strengthen knowledge of data provenance, model behaviour, and interpretability?

- How do I explain AI accurately and accessibly to non-specialists?

*Purpose:* Strengthen epistemic literacy and collective curiosity before moving into design or decision-making.

### **Domain 2 – Human–AI Co-Agency**

**Team reflection**

- Where do we rely on automation without questioning its appropriateness?

- Are human and AI responsibilities clearly defined and documented?

- How do we preserve professional judgement and accountability?

**Individual reflection**

- What do I delegate to AI—and why?

- How do I ensure transparency in shared decisions?

- How do I make my human contribution visible in co-authored or automated outputs?

*Purpose:* Reinforce intentional design of human oversight and clarify authorship, accountability, and value.

<span id="_mg8678po5g4z" class="anchor"></span>**  **

### **Domain 3 – Applied Practice and Innovation**

**Team reflection**

- Where could AI support new ideas, efficiency, or creativity?

- How do we balance curiosity with rigour and safety?

- Who is included or excluded in innovation discussions?

**Individual reflection**

- What low-risk experiment can I run to explore a new application responsibly?

- How do I record, share, and evaluate learning from experimentation?

- What does “ethical innovation” mean in my professional context?

*Purpose:* Encourage creative experimentation within ethical boundaries and collective learning.

### **Domain 4 – Ethics, Equity and Impact**

**Team reflection**

- Who benefits from our AI use—and who might be disadvantaged?

- Are our ethical principles integrated into workflows and governance, or treated as afterthoughts?

- How do we detect and respond to bias or unintended consequences?

**Individual reflection**

- What inequities might AI reinforce in my area of work?

- How do I ensure marginalised voices inform our design and decisions?

- Which ethical frameworks, declarations, or legal standards are most relevant?

*Purpose:* Embed proactive, justice-oriented ethics into day-to-day practice and oversight.

<span id="_m9akz18dlu2r" class="anchor"></span>**  **

### **Domain 5 – Decision-Making and Governance**

**Team reflection**

- How does AI influence or inform our organisational decisions?

- Are we transparent about when and how AI is used?

- Who validates or challenges system recommendations?

**Individual reflection**

- What does responsible AI decision-making look like in my role?

- Where might automation conceal complexity or human bias?

- How can I strengthen the visibility and contestability of governance decisions?

*Purpose:* Reinforce transparency, deliberation, and explainability across decision systems.

### **Domain 6 – Reflection, Learning and Renewal**

**Team reflection**

- What feedback loops currently exist?

- When did we last adapt a process based on reflection or user feedback?

- How do we share learning across projects or departments?

**Individual reflection**

- What assumptions about AI have shifted for me recently?

- How do I embed reflective habits into daily routines?

- What does collective learning and renewal look like in my organisation?

*Purpose:* Strengthen organisational memory, adaptive culture, and continuous improvement.

<span id="_x4fo1zjbi3nb" class="anchor"></span>**  **

## **7.2 Integrating Reflection**

Reflection functions as the **connective tissue** of capability. It links awareness to co-agency, innovation to ethics, and governance to renewal. When embedded intentionally, reflection converts individual insight into institutional learning.

**Integration strategies**

- **In CPD and training:** Pair reflection logs with capability reviews to capture qualitative growth.

- **In governance cycles:** Append reflection summaries to oversight reports or ethics board minutes.

- **In curriculum or service redesign:** Use reflection prompts to evaluate inclusivity, transparency, and long-term impact.

- **In leadership retreats:** Facilitate cross-domain reflection sessions to connect operational and strategic learning.

**Cultural conditions for effective reflection**

- **Openness:** Encourage psychological safety and candour.

- **Humility:** View uncertainty as an opportunity for learning, not weakness.

- **Iteration:** Treat reflection as an ongoing design activity rather than a post-project ritual.

When practiced consistently, reflection becomes an **ethical infrastructure**—a habitual process through which teams notice consequences, share learning, and renew trust. It turns capability from a checklist into a living culture of inquiry, ensuring that AI systems and human systems evolve together.

<span id="_xgk8r03fsgtd" class="anchor"></span>**  **

# **8. AI Interaction and Design Toolkit**

## **8.1 Purpose and Scope**

The **AI Interaction and Design Toolkit** enables the creation of effective, ethical, and context-aware interactions with intelligent systems of any kind. It moves beyond the narrow concept of *prompting* toward a systemic view of **interaction design** — the ways humans configure, question, interpret, and co-create meaning with AI.

AI systems do not merely provide answers; they **shape how meaning and knowledge are produced** through their interfaces, data structures, and feedback loops. Each interaction is therefore a design act that reflects human intention, organisational values, and ethical foresight.

Intentional interaction design is a **core capability** across all AI contexts — whether configuring a clinical diagnostic model, orchestrating a multi-agent workflow, building an educational recommender, or fine-tuning a conversational interface for student support.

This toolkit helps practitioners to:

- **Structure productive and ethical exchanges** with AI systems.

- **Align inputs with organisational purpose and social values.**

- **Develop interpretability and auditability**, ensuring that outputs can be reviewed and understood.

- **Translate technical complexity into human-centred use**, supporting transparency, creativity, and inclusion.

It can be applied to text, image, data, voice, sensor, multimodal, agentic, or future AI systems. The goal is to develop **design literacy** — not just technical skill — so that human oversight, intention, and meaning remain visible within automated processes.

<span id="_kal647kp3w97" class="anchor"></span>**  **

## **8.2 Toolkit Structure (by Domain)**

Each domain of the Framework brings a unique design focus and set of reflective questions. Together, they form an integrated design methodology for building transparent, auditable, and values-aligned human–AI systems.

### **Domain 1 – AI Awareness and Orientation**

**Design Goal:** Transparent understanding of how outputs are reached.  
**Considerations:** What system type is in use? What is known about its data sources, training assumptions, and limitations? How might interface design conceal or reveal reasoning?  
**Design Templates:**

- “Explain how this system reached its conclusion. What data or rules shaped this output?”

- “Highlight potential sources of uncertainty or bias.”

- “Compare this system-generated insight with a human expert’s interpretation — what differs and why?”  
  **Adaptation Tips:** Education (AI literacy exercises), Healthcare (clinical reasoning), Governance (policy transparency).

*Purpose:* Build **epistemic transparency** into everyday interactions so that users understand both *what* AI produces and *how* it produces it.

### **Domain 2 – Human–AI Co-Agency**

**Design Goal:** Clarity of roles, accountability, and meaningful oversight.  
**Considerations:** Which tasks remain human-led? Where does AI augment rather than replace expertise? How is authorship recorded?  
**Design Templates:**

- “Collaborate on \[task\]; I will review each step and provide context.”

- “Indicate where human interpretation or ethical review is required.”

- “Present alternative pathways reflecting different human priorities.”  
  **Adaptation Tips:** Research (co-design of analyses), Public services (role clarity), Management (co-decision logs).

*Purpose:* Make human intention and ethical reasoning *visible* within AI-enabled processes. Co-agency design ensures systems enhance rather than erode professional judgement.

### **Domain 3 – Applied Practice and Innovation**

**Design Goal:** Encourage exploration, creativity, and prototyping within ethical boundaries.  
**Considerations:** What outcomes are sought? Whose perspectives and risks are considered? How can prototypes remain transparent and reversible?  
**Design Templates:**

- “Propose three approaches to \[problem\] with trade-offs.”

- “Design a prototype workflow and highlight where human feedback is essential.”

- “List possible downstream effects and unintended consequences.”  
  **Adaptation Tips:** Teaching (curriculum prototypes), Healthcare (care-path simulations), Policy (scenario modelling).

*Purpose:* Foster **ethical experimentation** — treating design as inquiry rather than automation, encouraging creativity coupled with responsibility.

### **Domain 4 – Ethics, Equity and Impact**

**Design Goal:** Anticipate and mitigate harm, bias, or exclusion.  
**Considerations:** Who benefits or is burdened? Are marginalised perspectives represented in training data and validation processes? Does system output reinforce or challenge existing inequities?  
**Design Templates:**

- “Identify equity risks and propose mitigations.”

- “Simulate a stakeholder debate on ethical implications.”

- “Generate inclusion guidelines for teams deploying AI in \[sector\].”  
  **Adaptation Tips:** Policy (fairness audits), Education (values reflection), Healthcare (accessibility checks).

*Purpose:* Integrate **justice-by-design** into every stage of interaction — anticipating consequences and embedding inclusivity as a default condition, not a corrective measure.

<span id="_n804fss9sift" class="anchor"></span>**  **

### **Domain 5 – Decision-Making and Governance**

**Design Goal:** Ensure transparency, accountability, and participatory oversight.  
**Considerations:** What decisions are automated, assisted, or reviewed? Who can challenge system recommendations? What documentation and audit evidence are retained?  
**Design Templates:**

- “Create a decision map showing where system input occurs and who validates each stage.”

- “Draft an audit log explaining how this output was generated and what data it used.”

- “Model three governance options with benefits and risks.”  
  **Adaptation Tips:** Leadership (risk analysis), Compliance (AI use statements), Research (analysis documentation).

*Purpose:* Translate governance principles into practical **design artefacts** — logs, dashboards, and feedback systems that demonstrate explainability and accountability in action.

### **Domain 6 – Reflection, Learning and Renewal**

**Design Goal:** Embed feedback loops and continuous learning within AI use.  
**Considerations:** What evidence informs refinement? How are lessons captured and shared? Does the system evolve responsibly with new data?  
**Design Templates:**

- “Analyse the last five uses — what patterns or biases appear?”

- “Create a reflection log or dashboard for the team.”

- “Design a periodic review process for adapting use over time.”  
  **Adaptation Tips:** Education (formative reflection), Public services (policy iteration), Research (experiment tracking).

*Purpose:* Treat interaction as iterative learning. Reflection ensures that system behaviour and human practice co-evolve toward higher integrity and insight.

<span id="_687eww7l06l2" class="anchor"></span>**  **

## **8.3 Using the Toolkit**

Every engagement with AI is an act of **design**—a moment where intention, ethics, and interpretation meet. The toolkit helps convert everyday interactions into deliberate, auditable, and creative exchanges.

**Implementation guidance**

- **For workshops:** Use one domain at a time; pair prompts with live tool demonstrations or case reviews.

- **For project onboarding:** Apply the relevant design templates to define boundaries, oversight, and evaluation plans.

- **For governance planning:** Integrate toolkit outputs into decision logs, risk registers, or board papers.

- **For training and CPD:** Invite participants to adapt templates to their own roles and record insights for inclusion in reflection portfolios.

**Good practice principles**

- *Intentionality:* Design each prompt or workflow with a clear purpose and ethical rationale.

- *Relationality:* Recognise that human–AI interaction is a partnership, not a transaction.

- *Transparency:* Make assumptions, data origins, and decision pathways visible.

- *Iteration:* Review, test, and adapt prompts regularly to reflect new learning and system changes.

**Outcome:** When used consistently, the AI Interaction and Design Toolkit cultivates a culture of **responsible experimentation** and **transparent co-creation**. It transforms prompting from a technical trick into a professional discipline — a form of reflective design that strengthens trust, creativity, and accountability across all AI-enabled work.

<span id="_t7g12c4ezu78" class="anchor"></span>**  **

# **9. Scenario-Based Workshop Guides**

The **Scenario-Based Workshop Guides** translate each of the six domains of the CloudPedagogy AI Capability Framework into **practical, participatory learning experiences**.  
They are designed to help teams explore complex, real-world questions about AI adoption, ethics, and governance through structured dialogue, reflection, and design thinking.

Each scenario is built around five core components:

- **Scenario:** The realistic case or dilemma to investigate.

- **Objectives:** The specific learning and developmental aims.

- **Facilitation Notes:** Tips for structuring activities and guiding discussion.

- **Activities:** Interactive or analytical exercises.

- **Reflection Prompts:** Questions for individual or group debrief.

The guides can be adapted across **education, research, health, policy, and public-service** contexts. They work best when participants bring live challenges or ongoing projects, allowing the conversation to feed directly into action.

## **Domain 1 – AI Awareness and Orientation (Education)**

**Scenario:** A university department introduces AI-assisted tutoring tools. Staff express uncertainty about the accuracy of feedback and the reliability of recommendations.

**Objectives:**

- Develop shared understanding of how AI models generate and weight recommendations.

- Distinguish between perception, reasoning, and bias in outputs.

- Build confidence in communicating system limitations to students.

**Facilitation Notes:**

- Provide anonymised or simulated examples of AI tutoring feedback.

- Invite participants to identify visible and hidden assumptions in system reasoning.

- Compare outputs with human marking or mentoring commentary.

**  **

**Activities:**

1.  **Bias Mapping:** Participants annotate an AI-generated explanation, highlighting data or reasoning gaps.

2.  **Transparency Ladder:** Groups discuss how much explainability is sufficient for educational use.

3.  **Ethical Briefing Exercise:** Draft a short “AI literacy paragraph” to include in a course handbook.

**Reflection:**

- What surprised you about how the system reasoned or generalised?

- How can educators communicate these limitations responsibly?

- What new forms of literacy do students and staff require?

*Outcome:* Participants gain epistemic awareness—understanding not only what the system produces, but what kind of “knowledge” it represents.

## **Domain 2 – Human–AI Co-Agency (Healthcare)**

**Scenario:** A hospital is piloting an AI triage assistant. Clinicians must decide when to rely on the system’s advice and when to override it.

**Objectives:**

- Clarify shared responsibility between clinicians and automated systems.

- Preserve human judgement while harnessing data-driven insights.

- Document ethical and procedural boundaries for decision-making.

**Facilitation Notes:**

- Use a realistic but anonymised case study.

- Map moments of decision transfer between AI and human clinicians.

- Discuss consequences of over-reliance versus under-utilisation.

**  **

**Activities:**

1.  **Workflow Mapping:** Teams visualise points where AI input enters and where human validation occurs.

2.  **Oversight Charter:** Draft explicit “red-line rules” defining non-delegable clinical judgements.

3.  **Ethical Simulation:** Role-play a review board discussing a misclassification case.

**Reflection:**

- When did AI add value, and when did it risk eroding trust?

- How can documented co-agency protocols strengthen safety and accountability?

- What habits help clinicians maintain situational awareness?

*Outcome:* Participants articulate practical boundaries of shared agency, balancing augmentation with autonomy.

## **Domain 3 – Applied Practice and Innovation (Policy Design)**

**Scenario:** A city government explores AI to model climate-adaptation strategies. Teams must prototype explainable applications while addressing social equity.

**Objectives:**

- Use design thinking to create transparent AI prototypes.

- Evaluate potential applications through ethical and equity lenses.

- Balance innovation and accountability in public-sector experimentation.

**Facilitation Notes:**

- Provide open environmental data and stakeholder profiles.

- Emphasise iterative prototyping: quick sketches, test, feedback, refine.

- Encourage cross-disciplinary pairings (policy, data science, community).

**  **

**Activities:**

1.  **Ideation Sprint:** Generate multiple prototype ideas, then evaluate against ethics and sustainability criteria.

2.  **Stakeholder Canvas:** Map which communities benefit or risk exclusion.

3.  **Foresight Roundtable:** Discuss unintended consequences five years ahead.

**Reflection:**

- What insights or creative possibilities emerged?

- Which assumptions about data or fairness were challenged?

- What downstream effects might require governance attention?

*Outcome:* Innovation is reframed as *inquiry with consequences*—a balance of experimentation, evidence, and public value.

## **Domain 4 – Ethics, Equity and Impact (Research Governance)**

**Scenario:** A multidisciplinary research group uses AI to analyse participant data. Concerns arise about bias, consent, and the interpretation of outputs.

**Objectives:**

- Apply principles of justice, inclusion, and accountability to data use.

- Identify potential harms, exclusions, and mitigation strategies.

- Strengthen consent, provenance, and data-governance communication.

**Facilitation Notes:**

- Provide a mock ethics-application form for a hypothetical study.

- Discuss bias in dataset construction and model assumptions.

- Ensure participants consider accessibility and cultural representation.

**  **

**Activities:**

1.  **Bias Audit Drill:** Review dataset characteristics for representation gaps.

2.  **Consent Redesign:** Write a participant-friendly explanation of AI processing.

3.  **Perspective Exchange:** Rotate roles—researcher, participant, ethics reviewer—to uncover blind spots.

**Reflection:**

- Whose perspectives were absent from the design?

- How can ethical design improve every stage of the research lifecycle?

- What institutional supports are needed for ongoing fairness monitoring?

*Outcome:* Teams learn to embed equity and anticipatory ethics directly into the design and governance of research.

## **Domain 5 – Decision-Making and Governance (Institutional Governance)**

**Scenario:** A university board considers deploying AI for resource allocation. Members express concern about explainability and accountability.

**Objectives:**

- Identify ethical, operational, and reputational risks.

- Design oversight structures for transparent AI-informed decisions.

- Strengthen participatory governance through deliberative processes.

**Facilitation Notes:**

- Use a short case (e.g., AI-based workload allocation or funding model).

- Assign participants board roles: chair, ethics officer, faculty lead, data scientist.

- Debrief around competing values—efficiency, fairness, autonomy.

**  **

**Activities:**

1.  **Governance Mapping:** Visualise information flow and validation checkpoints.

2.  **Risk–Value Matrix:** Rank governance priorities using fairness, accountability, transparency criteria.

3.  **Audit Trail Simulation:** Draft a decision log with justification and human sign-off.

**Reflection:**

- Where should oversight remain non-delegable to AI?

- What documentation ensures explainability and public accountability?

- How can participatory governance enhance institutional trust?

*Outcome:* Participants convert abstract governance principles into operational accountability mechanisms.

## **Domain 6 – Reflection, Learning and Renewal (Organisational Learning)**

**Scenario:** A cross-faculty team reviews multiple AI pilots to develop an institutional AI strategy.

**Objectives:**

- Synthesise learning from diverse projects.

- Identify shared challenges, ethical themes, and knowledge gaps.

- Plan structures for continuous improvement and feedback.

**Facilitation Notes:**

- Collect short summaries of prior pilots (successes, surprises, failures).

- Use a structured **after-action review** format: *Worked / Surprised / Failed / Next.*

- Focus on system-level learning, not performance evaluation.

**  **

**Activities:**

1.  **Learning Harvest:** Group similar lessons and identify systemic patterns.

2.  **Capability Mapping:** Link insights to Framework domains to spot maturity levels.

3.  **Renewal Charter:** Draft an institutional statement on “learning from AI” practices.

**Reflection:**

- What cross-cutting themes or risks are emerging?

- How can these lessons shape future AI governance and capability building?

- What mechanisms ensure reflection leads to visible change?

*Outcome:* Reflection becomes an institutional process of renewal—an engine for sustainable, values-driven adaptation.

<span id="_icv96taommaa" class="anchor"></span>

## **9.1 Implementation Tips**

- **Scale flexibly:** Workshops can range from one-hour sessions to full-day retreats. Adjust activities to group size and complexity.

- **Mix roles:** Combine educators, technologists, administrators, and students (or equivalent cross-sector stakeholders) to encourage dialogue across boundaries.

- **Document learning:** Capture outcomes as shared artefacts—photos, reflection notes, decision logs—and store them in a common repository.

- **Close the loop:** Re-run the same scenario or a variant after 6–12 months to assess capability progression.

- **Link to governance:** Feed workshop insights into institutional policy reviews, ethics committees, or capability dashboards.

When used iteratively, these scenarios become **living laboratories** for ethical foresight and capability development. They transform workshops from awareness-raising exercises into structured cycles of reflection, governance, and renewal—turning everyday AI challenges into opportunities for collective learning and organisational evolution.

# **10. Applied Examples: The Framework in Action**

The following examples illustrate how the CloudPedagogy AI Capability Framework can be applied across education, healthcare, and public-service contexts. Each case shows how the six-domain model operates as a **living architecture**—guiding awareness, design, governance, and reflection from inception to renewal.

Rather than prescriptive models, these examples are **patterned narratives**—evidence that capability matures when ethics, co-agency, and reflection are intentionally designed into daily practice.

<span id="_ar7fu4z3pyvd" class="anchor"></span>

## **10.1 Education – Embedding Responsible AI in a New University Module**

**Context  **
A School of Social Sciences launches a new module, *AI, Society and Foresight*, aimed at helping students critically explore AI’s social impacts. Staff wish to integrate generative-AI tools for research exploration but are concerned about academic integrity, transparency, and assessment fairness.

**Process  **
The module team follows a structured capability pathway:

1.  **Orientation:** Begin with *Ethics, Equity and Impact*, *Human–AI Co-Agency*, and *Reflection & Renewal* domains to clarify boundaries and learning intentions.

2.  **Assessment:** Apply the **Self-Assessment Matrix** to map collective confidence and identify gaps in governance literacy.

3.  **Application:** Use the **AI Interaction and Design Toolkit** to prototype learning activities—e.g., prompting exercises framed around epistemic critique rather than content generation.

4.  **Governance:** Create an **AI Use Statement** that sets out expectations for students and staff, including transparency of tool use and citation norms.

5.  **Reflection:** Conclude each teaching block with structured reflective prompts asking students how AI influenced their thinking and reasoning processes.

**  **

**Outcomes**

- Learning outcomes explicitly reference ethics, transparency, and co-agency.

- Students complete *mini-audits* of their own AI use, producing reflexive commentaries alongside assignments.

- The module’s governance statement becomes a model for other departments.

**Reflection  **
Visible governance improved student trust and engagement. The framework gave staff a common language for cross-disciplinary design, shifting debate from “Should we use AI?” to “How do we use it responsibly and transparently?”

*Capability Trajectory:* Awareness → Co-Agency → Ethics → Governance → Reflection.

<span id="_l5cjqrs5mn30" class="anchor"></span>

## **10.2 Healthcare – Improving Patient Communication**

**Context  **
A regional healthcare network seeks to update patient-education materials in multiple languages using AI-assisted translation and summarisation. Initial trials produce inconsistent tone and inaccurate clinical terminology.

**Process**

1.  **Awareness:** Clinicians and communication officers examine AI translation models, identifying linguistic and cultural biases.

2.  **Co-Agency:** A tri-partnership is formed among clinicians, translators, and patient representatives to ensure mutual oversight.

3.  **Innovation:** Teams use the **AI Interaction Toolkit** to design translation workflows that highlight uncertainty and flag terms requiring review.

4.  **Equity Audit:** The **Ethics & Impact** domain guides a readability and accessibility review, ensuring materials suit diverse literacy levels.

5.  **Reflection:** A feedback loop is established, collecting patient responses and clinician edits for continuous refinement.

**  **

**Outcomes**

- Patient leaflets become culturally sensitive, readable, and medically accurate.

- Updates occur faster, but every change passes human validation.

- A shared **governance log** documents translation decisions and model revisions.

**Reflection  **
Efficiency alone did not build trust—**participatory oversight** did. Embedding human–AI partnership protocols strengthened both quality and confidence.

*Capability Trajectory:* Awareness → Co-Agency → Ethics → Governance → Reflection & Renewal.

<span id="_mvzxdtrtjtn4" class="anchor"></span>

## **10.3 Public Services – Data-Informed Policy Design**

**Context  **
A metropolitan transport authority uses AI analytics to plan routes for underserved neighbourhoods. Although data accuracy improves, community representatives question how fairness is measured.

**Process**

1.  **Awareness:** Planners examine the provenance and demographic balance of mobility data, recognising systemic gaps.

2.  **Governance:** A citizen oversight panel is established to review data assumptions and policy recommendations.

3.  **Ethics and Equity:** The team conducts an **Equity Audit** on model inputs, ensuring representation of low-income and mobility-impaired residents.

4.  **Innovation:** Iterative simulations model multiple route scenarios, visualising trade-offs between efficiency and accessibility.

5.  **Reflection:** Findings are published in an open annual report, inviting public commentary and follow-up reviews.

**  **

**Outcomes**

- Transparent policy briefs demonstrate how algorithmic insights were balanced against social priorities.

- Transport coverage for underserved areas improves measurably.

- Public trust increases through visible citizen participation and documentation.

**Reflection  **
The authority discovered that *transparency itself is a service*: by exposing assumptions and trade-offs, they gained legitimacy. Human values—equity, fairness, accountability—became part of the technical workflow.

*Capability Trajectory:* Awareness → Governance → Ethics → Reflection → Renewal.

<span id="_r24x11a2jsae" class="anchor"></span>

### **Cross-Case Insights**

Across all sectors, several recurring themes emerge:

- **Ethics as design practice:** Teams moved from reactive compliance to proactive value-shaping.

- **Co-agency as cultural infrastructure:** Clarity about roles and responsibilities turned abstract ethics into daily routines.

- **Reflection as renewal:** Periodic reviews transformed one-off projects into learning systems.

- **Transparency as trust:** When processes were documented and shared, participation and confidence grew.

Collectively, these examples demonstrate that the CloudPedagogy AI Capability Framework is more than a conceptual model—it is a **practical architecture** for capability growth.  
It connects everyday tasks to organisational foresight, enabling diverse sectors to engage AI **responsibly, creatively, and adaptively**.

<span id="_z9nichsiblz0" class="anchor"></span>**  **

# **11. Governance and Ethics Templates**

**Governance** is the connective architecture of responsible AI use.  
It ensures transparency, participation, and value alignment across systems, decisions, and institutional cultures. Within the CloudPedagogy AI Capability Framework, governance is not simply a compliance mechanism — it is a **design discipline** that links ethics, innovation, and learning into a coherent cycle of accountability and renewal.

The following templates provide practical scaffolding for building this connective architecture. They can be adapted for education, research, healthcare, public services, or corporate contexts.  
Each template functions both as a **living document** and a **learning instrument**, inviting critical dialogue, evidence gathering, and continual improvement.

<span id="_96f8lty7lzs8" class="anchor"></span>

## **11.1 Template A – AI Governance Protocol**

**Purpose:  **
To establish clear structures, accountability, and review processes for all AI-related activities, systems, or decisions within an organisation or project.

This protocol creates a shared record of purpose, oversight, and ethical assurance — turning abstract principles into actionable, auditable commitments.

### **Sections**

1.  **Scope and Purpose  **

    - Define the system(s) covered, including their purpose, scope, and intended benefits.

    - Name responsible owners, custodians, or leads for ethical, technical, and legal oversight.

    - Clarify alignment with institutional strategy, data governance, and social mission.

2.  **Ethically Informed Use-Case Review  **

    - Summarise purpose, expected benefits, and potential harms or risks.

    - Identify human oversight checkpoints across the workflow.

    - Record mitigations, contingency plans, and criteria for safe deactivation.

    - Include reference to applicable codes (e.g., institutional ethics policy, GDPR, UNESCO, OECD).

3.  **Role Mapping  **

    - Map decision authority and responsibility across all stages of AI deployment.

    - Identify consultation pathways: ethical, legal, and technical.

    - Specify how role information is communicated to internal and external stakeholders.

4.  **Transparency and Explainability  **

    - Document data provenance, model lineage, and interpretability processes.

    - Maintain *decision logs* describing when, how, and why AI input influenced outcomes.

    - Provide accessible explanations for affected individuals or oversight bodies.

5.  **Review and Escalation  **

    - Define triggers for review (e.g., performance anomalies, user complaints, ethical red flags).

    - Outline escalation lines to relevant governance bodies or senior management.

    - Establish criteria for halting, reconfiguring, or withdrawing systems.

6.  **Feedback and Learning  **

    - Integrate lessons from audits, user feedback, or reflective workshops.

    - Record when and how changes were implemented.

    - Specify review frequency (e.g., quarterly, annually) and responsible reviewer(s).

**Optional Add-Ons**

- Link to institutional **risk registers** or **ethics committee** documentation.

- Include an internal **self-assessment checklist** aligned with the six framework domains.

- Add a “Lessons Learned Log” for continuous improvement and CPD integration.

**Outcome:  **
When completed collaboratively, this protocol creates a **living governance record** — a transparent narrative of ethical stewardship that strengthens institutional trust and public legitimacy.

<span id="_700e2g3hzsen" class="anchor"></span>**  **

## **11.2 Template B – Equity-Focused AI Audit Tool**

**Purpose:  **
To assess and strengthen inclusion, fairness, and justice in the design, deployment, and review of AI systems or decisions.

This audit tool operationalises the *Ethics, Equity and Impact* domain, translating principles into concrete evaluative criteria. It can be applied to specific projects, datasets, workflows, or organisational policies.

### **Sections**

1.  **Representation and Access  **

    - Who benefits, and who may be excluded or harmed?

    - Does the system ensure equitable access for underrepresented or marginalised groups?

    - Are accessibility and language needs explicitly considered?

2.  **Participatory Design and Input  **

    - Who shaped requirements, data selection, and system evaluation?

    - Are lived experiences and community knowledge represented?

    - Were stakeholders consulted in ways that allowed genuine influence?

3.  **Data and Model Sensitivities  **

    - Identify known limitations, biases, or blind spots in training data and model design.

    - Describe monitoring and correction mechanisms for bias and drift.

    - Ensure transparency of model updates and validation methods.

4.  **Feedback and Challenge Mechanisms  **

    - Are contestation routes available for affected users or communities?

    - How is feedback collected, analysed, and acted upon?

    - Are appeal outcomes visible and traceable?

5.  **Power and Shared Governance  **

    - Map decision-making authority across stakeholders.

    - Are impacted groups included in advisory, audit, or co-design processes?

    - What safeguards exist to prevent concentration of power or exclusion?  
      <span id="_wax71rnuz958" class="anchor"></span>

### **Scoring (optional)**

Use a four-level developmental scale to guide qualitative discussion rather than compliance grading:

|  |  |  |
|:------:|:-----------------:|:--------------------------------------------:|
| **Score** | **Descriptor** | **Meaning** |
| 1 | **Not Addressed** | Area not yet considered or documented. |
| 2 | **Emerging** | Some awareness; plans forming but no implementation. |
| 3 | **Adequate** | Processes established and monitored. |
| 4 | **Exemplary & Ongoing** | Practices embedded and regularly reviewed through lived feedback. |

### **Deliverables**

- **Audit Summary Report** highlighting strengths, gaps, and recommendations.

- **Mitigation Plan** outlining remedial actions, timelines, and responsible parties.

- **Integration Notes** connecting audit findings to CPD programmes, ethics reviews, or policy updates.

**Outcome:  **
Used iteratively, the Equity-Focused AI Audit becomes an engine of **inclusive accountability**, enabling systems and institutions to evolve toward justice, accessibility, and participatory design.

<span id="_pwoa7kly77wh" class="anchor"></span>**  **

## **11.3 Using These Templates**

Governance and ethics templates are most effective when integrated **early** — during the design or concept stage — rather than retrofitted after deployment. They function as *conversation frameworks* as much as compliance records.

### **Practical Integration Strategies**

- **Workshops:** Use the templates in multidisciplinary sessions to surface assumptions and align priorities.

- **Project Reviews:** Apply them before key decision points (e.g., procurement, launch, scaling).

- **Governance Boards:** Incorporate them into agendas as standing items to embed foresight in oversight.

- **Training and CPD:** Include case-based exercises using these templates for reflective learning.

- **Iteration:** Revisit documents regularly—treat them as dynamic artefacts reflecting organisational learning.

### **Cultural Principles for Effective Governance**

- **Co-ownership:** Share responsibility across disciplines and hierarchies, avoiding siloed oversight.

- **Transparency:** Keep governance documentation open wherever possible; secrecy undermines legitimacy.

- **Dialogue over audit:** Use these tools to support ethical reasoning, not to generate punitive metrics.

- **Continuous foresight:** View governance as a *learning process* that evolves alongside technology and context.

When these templates are used consistently, governance becomes **developmental, not defensive**—a participatory practice of care and accountability that strengthens both human agency and institutional integrity.

<span id="_hy736etu0u7y" class="anchor"></span>**  **

# **12. Resources and Further Development**

The **CloudPedagogy AI Capability Framework** is designed as a *living resource*—a structure that matures through practice, collaboration, and reflection.  
Its strength lies not only in the conceptual model but in the community that applies, critiques, and extends it.  
This section outlines the ongoing and future resources that will support adoption, capacity-building, and evidence-based improvement across sectors.

## **12.1 In Development**

CloudPedagogy is continuously expanding the Framework’s ecosystem of applied resources to ensure accessibility, adaptability, and measurable growth in capability.

**1. Digital Badges and Microcredentials**

- Recognition aligned to each of the six domains, rewarding demonstrated practice rather than passive completion.

- Criteria linked to the **Self-Assessment Matrix** and **Reflection Toolkit** outcomes.

- Stackable across roles (educator, researcher, policymaker, practitioner) to form professional-learning pathways.

**2. Pilot Case Studies and Sector Examples**

- Documented pilots from universities, healthcare systems, NGOs, and public agencies.

- Each case will illustrate domain interdependence, ethical decision-making, and iterative capability growth.

- Summaries published as open exemplars to inspire adaptation across cultures and disciplines.

**3. Facilitator Kits and Workshop Packs**

- Slide decks, scenario cards, and reflection templates to help teams run their own workshops.

- Pre-structured agendas (1 hour / half-day / full-day formats).

- Guidance for embedding the six-domain language within CPD or institutional-change programmes.

**4. Open-Source Templates**

- Editable versions of all matrices, toolkits, and audit forms (CC BY-NC-SA 4.0).

- Modular components for integration with existing governance, learning, or policy systems.

- Shared via [<u>cloudpedagogy.com</u>](https://cloudpedagogy.com) and GitHub for community co-development.

**5. Integrated Intelligent Tools (Planned)**

- Interactive dashboards for visualising capability progression across teams.

- AI-supported **scenario simulators** for foresight and ethical decision practice.

- Reflective-learning engines linking framework domains to real-time organisational feedback.

Together, these resources transform the Framework from a static publication into an evolving infrastructure for responsible and creative AI engagement.

## **12.2 Invitation to Collaborate**

The Framework’s value grows through *collective authorship*.  
CloudPedagogy invites institutions, practitioners, and researchers to:

- **Contribute case studies** demonstrating use of the Framework in local or national contexts.

- **Co-develop new components** such as domain-specific matrices or culturally adapted reflection guides.

- **Translate or localise** materials for multilingual and cross-sector audiences.

- **Pilot digital-badge systems** or run **community workshops** for shared evaluation.

**Contact:  **
🌐 [<u>cloudpedagogy.com  
</u>](https://cloudpedagogy.com) 📧 info@cloudpedagogy.com  
📧 (Project Lead) jonathan@cloudpedagogy.com

Collaboration is guided by open principles—shared learning, transparent crediting, and reciprocal improvement.

<span id="_g4hsapez5up8" class="anchor"></span>**  **

## **12.3 Integration within the CloudPedagogy Platform**

All Framework resources are embedded within the **CloudPedagogy learning ecosystem**, designed for flexible, self-paced, and community-based engagement:

- **Self-paced courses** aligned to each domain, providing structured progression from orientation to mastery.

- **Downloadable toolkits and scenario cards** for immediate institutional use.

- **Optional certification** and **reflective portfolios** documenting evidence of growth.

- Future integration with **AI-supported learning tools** that enable dynamic assessment and feedback.

Together these features embody the Framework’s developmental pathway:  
**Orient → Assess → Apply → Reflect → Iterate.**

## **12.4 Attribution and Licensing**

© 2026 CloudPedagogy. Licensed under CC BY-NC-SA 4.0 (Attribution – NonCommercial – ShareAlike).

This Framework builds upon and extends key international initiatives:

- **Jisc Digital Capabilities (UK)**

- **DigComp (EU)**

- **EDUCAUSE Digital Dexterity and AI Literacy (US)  **

CloudPedagogy expands these models into the domains of **AI literacy**, **governance**, and **generative capability**, offering a developmental architecture for human-centred AI practice.

<span id="_wi3noiiky6au" class="anchor"></span>**  **

## **12.5 Closing Note**

AI capability is not a fixed competence but a *practice of inquiry, ethics, and renewal*.  
As intelligent systems evolve, so too must the ways we learn, decide, and govern.  
The challenge—and opportunity—lies in cultivating reflective intelligence that matches technological complexity with human foresight, empathy, and creativity.

The CloudPedagogy AI Capability Framework offers a foundation, not a conclusion: a shared vocabulary for building futures that remain equitable, intelligible, and humane.  
Use it. Adapt it. Evolve it in your context.

## **12.6 Measuring Impact (Suggested Indicators)**

To evaluate both capability growth and organisational learning, institutions may track the following indicators:

1.  **Engagement and Reach  **
     • % of teams completing the Self-Assessment Matrix every 6–12 months.

2.  **Applied Practice  **
     • Number of scenario-based workshops piloted and documented.

3.  **Governance Maturity  **
     • Presence of AI Use Statements, decision logs, and oversight records across projects.

4.  **Equity and Ethics Integration  **
     • Number of equity-audit actions closed per review cycle.

5.  **Capability Confidence  **
     • Pre/post assessment shifts in staff confidence within each domain.

6.  **Learning Sustainability  **
     • Proportion of governance reviews completed on schedule with documented learning updates.

These indicators should be interpreted *developmentally*, signalling progress in culture and reflection rather than compliance performance.

## **12.7 How to Cite**

Wong, J. (2026). *CloudPedagogy AI Capability Framework (2026 Edition).* CloudPedagogy. CC BY-NC-SA 4.0.

<span id="_z0adzw4ovn23" class="anchor"></span>**  **

# **13. Glossary**

This glossary defines key terms used throughout the **CloudPedagogy AI Capability Framework (2026 Edition)**. Each term is framed to reflect the developmental and ethical intent of the Framework—emphasising human–AI relationships, transparency, and systemic understanding rather than purely technical description.

**AI system  **
Any software or hardware capable of perception, reasoning, or action that influences human or organisational outcomes.  
Includes generative, predictive, agentic, multimodal, and hybrid forms of artificial intelligence.

**AI interaction design  **
The intentional practice of shaping inputs, configurations, and feedback processes to enable meaningful, auditable, and ethically aligned engagement with AI systems.  
Extends beyond “prompting” to include interpretability, co-agency, and reflective oversight.

**AI capability (capability)  **
The developmental ability to understand, shape, and govern AI systems with ethical, creative, and systemic awareness.  
In the Framework, capability evolves across six interdependent domains rather than through fixed skill acquisition.

**AI awareness  **
Foundational literacy about how AI systems perceive, reason, and decide, including recognition of their assumptions, limitations, and social implications.  
Serves as the entry point for critical engagement and informed decision-making.

**Co-agency (human–AI)  **
The purposeful distribution of roles, responsibilities, and decision authority between humans and AI systems.  
Co-agency ensures that human judgement, context, and ethics remain central while leveraging machine capabilities for augmentation and insight.

**Interpretability  **
The extent to which an AI system’s inner reasoning, data use, and decision outputs can be understood and explained by humans.  
A foundation for transparency, trust, and responsible governance.

**Traceability  **
The ability to reconstruct the sequence of inputs, data sources, configurations, and decisions that led to a particular outcome.  
Enables auditability, accountability, and ethical review.

**Transparency  **
The degree to which AI processes, data sources, and decision pathways are visible, explainable, and open to scrutiny by stakeholders.  
Transparency strengthens legitimacy and public trust.

**Ethics (AI ethics)  **
The continuous practice of aligning AI design and use with human values, fairness, and accountability.  
Extends beyond compliance to anticipatory and participatory foresight.

**Equity audit  **
A structured process for assessing fairness, inclusion, and justice across the lifecycle of AI design, deployment, and evaluation.  
Identifies who benefits, who is excluded, and how structural inequalities may be mitigated.

**Governance (AI governance)  **
The structures, policies, and participatory processes that ensure accountable, transparent, and values-aligned oversight of AI systems.  
Encompasses ethical review, documentation, escalation, and continuous learning.

**Governance artefact  **
A tangible record or mechanism—such as an AI Use Statement, audit log, or oversight protocol—that documents how AI-influenced decisions are guided, reviewed, and justified.

**Innovation (applied practice and innovation)  **
The process of experimenting and creating with AI responsibly.  
Combines curiosity, ethics, and contextual adaptation to generate new insights, services, or practices while safeguarding inclusion and accountability.

**Foresight  **
The capacity to anticipate future consequences, opportunities, and ethical implications of AI systems.  
Supports proactive design, strategic planning, and sustainable decision-making.

**Ecological learning  **
An approach to capability development that views knowledge as relational, adaptive, and situated within systems of people, tools, and contexts.  
Serves as a philosophical foundation for reflection and renewal.

**Learning ecosystem  **
The interconnected network of people, processes, technologies, and feedback loops through which organisations learn and adapt in response to AI.  
Transforms individual reflection into collective capability.

**Design thinking  **
A human-centred methodology for creative problem-solving, emphasising empathy, prototyping, iteration, and testing.  
Within the Framework, design thinking provides the mode through which AI capability becomes reflective and adaptive.

**Reflective intelligence  **
The capacity to question, analyse, and adapt one’s use of AI over time.  
Anchors continuous improvement, ethical foresight, and renewal across all six domains.

**Values-in-practice  **
The lived enactment of ethical, cultural, and organisational principles in daily AI-enabled work.  
Translates institutional values—such as equity, care, or transparency—into observable behaviour and decision-making patterns.

**Note:  **
This glossary is non-exhaustive and intended to evolve with each Framework edition. Users are encouraged to expand or adapt definitions for local, disciplinary, or linguistic contexts.

# 
