# **AI Capability Practice Guide: Governance & Decision-Making**

**Accountable, Transparent, and Defensible AI Use for Decisions That Matter**

## **Stage 1 â€” Orientation & Fast Start (Governance & Decision-Making)**

## **Who This Guide Is For**

This guide is for people who are **formally responsible for decisions, oversight, and accountability** where AI may shape outcomes.

This includes:

- academic and professional decision-makers

- governance leads and committee members

- programme directors and portfolio owners

- policy, compliance, and QA leads

- risk, assurance, and audit functions

- leaders accountable to boards, regulators, or the public

You may not personally operate AI tools.  
You **are** responsible for:

- decisions AI influences

- how those decisions are justified

- how risk is managed

- how accountability is demonstrated

This guide assumes **scrutiny is real** and justification may be required months or years later.

## **Who This Guide Is Not For**

This guide is **not** designed for:

- technical system design or model evaluation

- prompt engineering or tool optimisation

- informal experimentation with no accountability

- delegating responsibility to â€œthe modelâ€

- retroactive justification after harm occurs

If your aim is to use AI **without traceability or oversight**, this guide will feel deliberately uncomfortable.

**  **

## **What You Will Be Able to Do in 30â€“60 Minutes**

By working through this guide, you will be able to:

- determine **when AI use triggers governance requirements**

- distinguish low-risk support from **decision-shaping influence**

- apply **proportionate oversight** without bureaucracy

- design **transparent, contestable decision processes**

- document AI influence in ways that stand up to scrutiny

- know **when to escalate, pause, or prohibit AI use**

You will also produce at least **one concrete governance artefact** (e.g. a decision note, escalation trigger list, or accountability map) you can reuse immediately.

## **FAST START â€” USE THIS NOW**

If you read only one section, read this one.

This Fast Start enables **defensible AI-informed decisions** in **10 minutes**, even under pressure.

### **When to Use This Guide**

Use this guide when:

- AI influences approval, prioritisation, or judgement

- decisions affect people, access, resources, or outcomes

- an AI-informed recommendation is hard to interrogate

- you may be asked later: *â€œHow was this decision made?â€*

- responsibility sits with youâ€”even if analysis came from elsewhere

- consequences would be difficult to undo

If AI affects **decisions others must live with**, governance applies.

## **The 10-Minute Entry Workflow (Governance)**

Use this sequence **before** approving, rejecting, or ratifying an AI-influenced decision.

### **Step 1 â€” Name the Decision Clearly**

Write:

> *â€œThis decision concerns: \[specific decision being taken\].â€*

Examples:

- approving a policy change

- allocating funding

- authorising AI deployment

- endorsing an assessment method

Unclear decisions produce ungovernable risk.

**  **

### **Step 2 â€” Identify AI Influence (Not Just Use)**

Ask:

- Did AI **inform, frame, rank, or recommend** options?

- Did it influence interpretation, not just presentation?

- Could the decision reasonably have been made without AI?

If AI influence is unclear, the decision is **not governance-ready**.

### **Step 3 â€” Apply the Decision Risk Screen**

Ask:

- Who is affected by this decision?

- Is harm reversible?

- Would I be comfortable defending this process publicly?

High impact or low reversibility = higher governance.

### **Step 4 â€” Set the Governance Level**

Choose one:

âœ… **Proceed with documented oversight  **
ðŸ” **Request clarification, evidence, or alternatives  **
â›” **Pause or escalate** (ethics, legal, board, regulator)

Record the rationale briefly.

**  **

### **Step 5 â€” Create a Minimal Decision Record**

Capture:

- the decision

- the role of AI

- the human authority

- risks considered

If it isnâ€™t recorded, it effectively didnâ€™t happen.

## **Worked Example â€” One Decision, Three Outcomes (Governance)**

**Decision**
Using AI-supported analysis to prioritise service access.

### **âœ… Good Use**

- AI informs options

- Decision-makers interrogate assumptions

- Equity and impact are examined

- Decision process is documented

**Why this works:**
AI informs without obscuring accountability.

**  **

### **âš ï¸ Risky Use**

- AI ranking is accepted largely as-is

- Limited documentation

- Governance is informal

**Why this is risky:**
Challenges later cannot be answered clearly.

### **â›” Unacceptable Use**

- AI output is treated as objective truth

- No clear decision owner

- No decision record

**Why this fails:**
Accountability has been displaced.

## **Your First Governance Artefact (Create This Now)**

Write a **Decision Accountability Note** (3â€“5 lines):

- Decision being taken

- Role of AI

- Human decision-maker

- Oversight applied

- Escalation required (if any)

This single note dramatically increases defensibility.

## **How This Guide Works**

This guide supports **real governance under real constraints**.

You are not expected to apply everything every time.  
You are expected to:

- intervene when AI shapes decisions

- make authority visible

- ensure proportional oversight

- protect legitimacy and trust

## **The Six Domains as a Governance Workflow**

In governance contexts, the six domains act as **accountability safeguards**:

- **AI Awareness & Orientation** â€” Knowing what AI influence actually means

- **Humanâ€“AI Co-Agency** â€” Making authority and responsibility explicit

- **Applied Practice & Innovation** â€” Allowing use without bypassing oversight

- **Ethics, Equity & Impact** â€” Anticipating harm and unfairness

- **Decision-Making & Governance** â€” Ensuring traceability and escalation

- **Reflection, Learning & Renewal** â€” Improving governance over time

Skipping domains doesnâ€™t speed decisions.  
It transfers risk to those least able to contest it.

## **Stage 2 â€” How This Guide Works & Situational Entry Points (Governance & Decision-Making)**

## **HOW THIS GUIDE WORKS**

This guide is designed for **formal decision contexts** where AI may shape outcomes and where **accountability must be demonstrable**.

You are **not** expected to read this guide cover-to-cover.  
You are expected to:

- enter when an AI-influenced decision is being proposed or reviewed

- apply only the checks proportionate to risk

- make authority, rationale, and oversight visible

- move decisions forward with legitimacy intact

This mirrors real governance practice:  
decisions are time-bound, contested, and reviewed later.

**  **

## **The Six Domains as a Governance Decision Framework**

The AI Capability Framework consists of six domains.  
In governance contexts, these function as **checks on power and process**.

You apply **more domains as impact, irreversibility, or uncertainty increases**.

### **The Governance Capability Flow**

- **AI Awareness & Orientation**
  Understand *how* AI influenced the decisionâ€”not just that it was used.

- **Humanâ€“AI Co-Agency**
  Make authority and accountability explicit and non-transferable.

- **Applied Practice & Innovation**
  Permit AI use without bypassing oversight or due process.

- **Ethics, Equity & Impact**
  Identify who bears risk, who benefits, and who can contest outcomes.

- **Decision-Making & Governance**
  Ensure traceability, documentation, and proportionate escalation.

- **Reflection, Learning & Renewal**
  Improve decision systems over time; avoid repeating unseen failures.

Skipping domains rarely saves time.  
It usually increases downstream challenge, delay, or harm.

**  **

## **Why Situational Entry Points Matter in Governance**

Governance rarely begins with a clean slate.  
It usually begins with:

- a paper already written

- a recommendation already favoured

- an AI-backed analysis no one fully understands

- pressure to approve quickly

- concern about challenge or review later

Situational entry points let you intervene **where governance pressure actually appears**.

**  **

# **SITUATIONAL ENTRY POINTS â€” START HERE**

Choose the entry point that most closely fits your situation.  
Each one indicates which domains to prioritise and what to do now.

## **Entry Point 1 â€” â€œThis recommendation is persuasive, but opaque.â€**

AI-informed advice looks strong, but the reasoning is hard to interrogate.

### **Primary domains to apply**

- **AI Awareness & Orientation**

- **Humanâ€“AI Co-Agency**

### **What to do now**

- Ask how AI shaped the recommendation (ranked, clustered, forecasted?)

- Identify assumptions, data gaps, and limitations

- Confirm which human authority owns the final judgement

### **Common failure mode**

- Treating opacity as inevitable or acceptable

**  **

## **Entry Point 2 â€” â€œThis decision affects people who cannot contest it.â€**

The decision impacts:

- access or opportunity

- evaluation or assessment

- services or benefits

### **Primary domains to apply**

- **Ethics, Equity & Impact**

- **Decision-Making & Governance**

### **What to do now**

- Identify who is affected and how

- Examine fairness, bias, and exclusion risk

- Decide what disclosure, review, or appeal mechanisms are required

### **Common failure mode**

- Assuming technical accuracy equates to fairness

**  **

## **Entry Point 3 â€” â€œAI is shaping judgement, not just informing it.â€**

AI influence goes beyond presentation into **choice or prioritisation**.

### **Primary domains to apply**

- **Humanâ€“AI Co-Agency**

- **Decision-Making & Governance**

### **What to do now**

- Clarify which judgements must remain human-owned

- Require documentation of how AI influenced options

- Prevent silent delegation

### **Common failure mode**

- Letting influence accumulate without explicit approval

**  **

## **Entry Point 4 â€” â€œIf challenged, we need to justify this decision.â€**

You anticipate scrutiny from:

- auditors or QA

- ethics committees

- regulators

- courts or tribunals

- public inquiry

### **Primary domains to apply**

- **Decision-Making & Governance**

- **Ethics, Equity & Impact**

### **What to do now**

- Ensure a clear decision record exists

- Document AIâ€™s role and human reasoning

- Verify oversight and escalation were appropriate

### **Common failure mode**

- Trying to reconstruct justification after the fact

**  **

## **Entry Point 5 â€” â€œAI use is becoming routine across decisions.â€**

AI is normalised in:

- approval pipelines

- triage or prioritisation

- monitoring or evaluation

### **Primary domains to apply**

- **Applied Practice & Innovation**

- **Reflection, Learning & Renewal**

### **What to do now**

- Identify patterns of risk across decisions

- Adjust governance thresholds

- Establish review and feedback loops

### **Common failure mode**

- Scaling AI use faster than governance maturity

**  **

## **Entry Point 6 â€” â€œI want governance that enables, not blocks, good decisions.â€**

You are aiming for:

- proportionate oversight

- institutional trust

- decision velocity *with* legitimacy

### **Primary domains to apply**

- **Applied Practice & Innovation**

- **Decision-Making & Governance**

### **What to do now**

- Differentiate low-risk support from decision-shaping use

- Standardise lightweight documentation

- Clarify when formal review is truly required

### **Common failure mode**

- Over-governing low-risk use while under-governing high-risk decisions

**  **

## **How the Rest of This Guide Is Structured**

From here, the guide moves into the **Core Practice Workflow**, applying the six domains directly to governance and decision-making.

Each domain section will:

- explain what it protects at governance level

- provide immediate application questions

- include practical governance tools

- identify common governance failures

- include a short reflection prompt

You can use:

- one domain for rapid checks

- several domains for complex decisions

- all six for high-impact or irreversible outcomes

**  **

## **Stage 3 â€” Core Practice Workflow: Domains 1â€“3 (Governance & Decision-Making)**

*Ensuring Decisions Influenced by AI Remain Accountable, Transparent, and Legitimate*

Domains 1â€“3 determine whether AI is used **within** governance â€” or quietly bypasses it.

At governance level, failure rarely comes from technical error.  
It comes from **blurred authority, invisible influence, and unexamined assumptions**.

Each domain follows the canonical structure used across the Practice Guides.

# **DOMAIN 1 â€” AI Awareness & Orientation (Decision Transparency)**

## **What This Domain Protects**

This domain protects governance from:

- treating AI influence as neutral or â€œjust technicalâ€

- accepting outputs without understanding how they were produced

- mistaking analytical sophistication for legitimacy

- allowing opaque systems to shape contested decisions

- underestimating uncertainty embedded in models

In governance contexts, awareness is about **traceability**, not mechanics.

If decision-makers cannot explain *how* AI shaped a decision, governance has already failed.

**  **

## **Apply Now â€” Key Questions**

Before approving or ratifying any AI-influenced decision, ask:

1.  **How exactly did AI influence this decision?**
    (Informing, ranking, filtering, forecasting, recommending?)

2.  **Which assumptions, proxies, or data boundaries are embedded?**
    (What was included? What was excluded?)

3.  **What uncertainty or confidence limits apply?**
    (What is unknown or estimated?)

4.  **Where could a confident but wrong output cause harm?**
    (Access, fairness, safety, trust.)

If these cannot be answered, pause the decision.

## **Tool in Use â€” AI Influence Statement**

Require a short, standardised statement in decision papers:

**AI Influence Statement**

- **Purpose of AI use:**

- **Type of influence:** inform / rank / predict / recommend

- **Key assumptions or limitations:**

- **Human judgement applied:**

This turns opaque influence into governable input.

**  **

## **Common Failure Modes in Governance**

- citing AI without explaining its role

- assuming oversight occurs elsewhere

- using technical language to deflect scrutiny

- confusing explanation with justification

- normalising opacity through repetition

## **Quick Reflection**

**If challenged, could I clearly explain this AI influence in plain language?**

**  **

# **DOMAIN 2 â€” Humanâ€“AI Co-Agency (Authority & Accountability)**

## **What This Domain Protects**

This domain protects:

- clarity of decision ownership

- legal and ethical accountability

- institutional legitimacy

- the right to challenge or appeal

In governance, **accountability cannot be distributed to systems**.

No matter how complex the analysis, authority must remain human and named.

## **Apply Now â€” Key Questions**

Ask:

1.  **Who is the decision-maker of record?**

2.  **What judgement was exercised by humansâ€”not AI?**

3.  **Could accountability be disputed later?**

4.  **Is responsibility shared or unclear across committees?**

If any answer is unclear, governance risk is present.

**  **

## **Tool in Use â€” Decision Authority Map**

Clarify roles explicitly:

**Decision Authority Map**

- **AI contributes:**

- **Humans decide:**

- **Accountable authority:**

This prevents silent diffusion of responsibility.

## **Common Failure Modes in Governance**

- attributing outcomes to â€œthe modelâ€

- spreading accountability across groups without clarity

- relying on consensus to mask authority

- retroactively assigning responsibility

- assuming legal ownership equals ethical ownership

## **Quick Reflection**

**Is accountability explicit, singular, and defensible?**

# **DOMAIN 3 â€” Applied Practice & Innovation (Governed Use Without Paralysis)**

## **What This Domain Enables**

This domain enables organisations to **use AI productively** without undermining governance.

It allows:

- AI-assisted analysis

- pilot and exploratory use

- iterative decision support

without creating:

- decision laundering

- automation without oversight

- governance paralysis

Innovation here means **designed permission**, not uncontrolled experimentation.

## **Apply Now â€” Key Questions**

Ask:

1.  **Is this AI use appropriate for the decisionâ€™s risk level?**

2.  **Are we allowing flexibility where risk is low?**

3.  **Have we imposed controls where impact is high?**

4.  **Is governance enabling or obstructing good decisions?**

Over-governance and under-governance are equally risky.

## **Tool in Use â€” Governance Tiering Model**

Apply proportional oversight:

**Low-Risk Decisions**

- AI assists with background analysis

- Minimal documentation

- Local approval

**Medium-Risk Decisions**

- AI informs options

- Decision note required

- Named authority

**High-Risk Decisions**

- AI influence fully documented

- Ethics or legal review

- Escalation and appeal pathways

Tier first. Govern second.

**  **

## **Common Failure Modes in Governance**

- applying the same controls to all AI use

- allowing pilots to become de facto policy

- freezing innovation through fear

- failing to revisit governance as use scales

- assuming once-approved equals forever-safe

## **Quick Reflection**

**Does our governance fit the riskâ€”or has it drifted?**

# **Domains 1â€“3 in Practice (Governance & Decision-Making)**

Together, Domains 1â€“3 ensure that:

- AI influence is visible, not hidden

- accountability is clear and contestable

- innovation is possible without bypassing oversight

They are the foundation of **trustworthy AI-mediated decisions**.

As impact and scrutiny increase, these domains must be complemented by Domains 4â€“6:

- ethics

- equity

- governance resilience

- long-term learning

## **Stage 4 â€” Risk, Responsibility & Renewal: Domains 4â€“6 (Governance & Decision-Making)**

*Ensuring Fairness, Legitimacy, and Long-Term Accountability in AI-Influenced Decisions*

Domains 4â€“6 address the **hardest problems in governance**:  
who bears risk, how harm is prevented or corrected, and how institutions learn rather than repeat mistakes.

These domains ensure that AI does not quietly erode trust, fairness, or accountability as its use normalises.

**  **

# **DOMAIN 4 â€” Ethics, Equity & Impact (Fairness and Contestability)**

## **What This Domain Protects**

This domain protects:

- individuals and groups affected by decisions

- equitable access to opportunities, services, or outcomes

- the right to challenge, appeal, or contest decisions

- public confidence in institutional decision-making

In governance contexts, ethics is not abstract principle.  
It is about **who bears the consequences**.

AI-mediated decisions can:

- scale harm quickly

- obscure responsibility

- limit avenues for redress

Ethical governance ensures **those affected are considered and protected**.

**  **

## **Apply Now â€” Key Questions**

Before finalising AI-influenced decisions, ask:

1.  **Who is affected by this decision, directly and indirectly?**

2.  **Are some groups more exposed to risk or exclusion?**

3.  **Can those affected understand or challenge the outcome?**

4.  **Does AI reduce or increase transparency for those impacted?**

5.  **Would harm be detectable earlyâ€”or only after damage occurs?**

Ethics must be applied **before** decisions are locked in.

## **Tool in Use â€” Governance Equity & Impact Scan**

Use this short scan for any decision affecting people or access:

**Equity & Impact Scan**

- **Affected groups:** Who may be impacted?

- **Differential impact:** Who bears more risk or cost?

- **Contestability:** Can decisions be challenged or reviewed?

- **Visibility of harm:** How quickly would issues surface?

Document one sentence per item.

**  **

## **Common Failure Modes in Governance**

- assuming procedural fairness guarantees outcome fairness

- dismissing equity concerns as â€œsubjectiveâ€

- focusing on intent rather than lived impact

- overlooking those with least power to challenge decisions

- failing to design appeal or review mechanisms

## **Quick Reflection**

**If I were affected by this decision, how easy would it be to question it?**

**  **

# **DOMAIN 5 â€” Decision-Making & Governance (Defensibility Under Scrutiny)**

## **What This Domain Protects**

This domain protects:

- institutional credibility

- legal defensibility

- audit readiness

- consistency across decisions

- institutional memory

Governance must ensure decisions are:

- explainable

- documented

- reviewable

- proportionate to risk

AI adds complexity â€” governance must add clarity.

**  **

## **Apply Now â€” Key Questions**

Ask:

1.  **What documentation is required for this decisionâ€™s risk level?**

2.  **Is the rationale clear without technical expertise?**

3.  **Who reviewed or approved the AI influence?**

4.  **How would this decision be explained externally?**

5.  **Is this consistent with similar past decisions?**

Inconsistency creates challenge risk.

## **Tool in Use â€” Decision Defensibility Record**

For any consequential AI-influenced decision, capture:

**Decision Defensibility Record**

- **Decision outcome:**

- **Purpose and context:**

- **Role of AI:**

- **Human reasoning applied:**

- **Risks and mitigations:**

- **Review or appeal pathway:**

Store where it can be retrieved later.

**  **

## **Escalation & Review Triggers**

Escalate or require additional review when AI affects:

- access to rights, services, or benefits

- grading, evaluation, or eligibility

- policy interpretation

- disciplinary or adverse outcomes

- public-facing or reputational decisions

- legally or regulatorily sensitive areas

If escalation feels inconvenient, governance is most needed.

## **Common Failure Modes in Governance**

- incomplete or inconsistent records

- governance decisions made in email or verbally only

- documentation that explains *what* but not *why*

- assuming legal review equals ethical review

- governance that cannot be reproduced later

**  **

## **Quick Reflection**

**Could this decision be defended clearly in six monthsâ€™ time?**

# **DOMAIN 6 â€” Reflection, Learning & Renewal (Institutional Capability)**

## **What This Domain Sustains**

This domain sustains:

- organisational learning

- adaptive governance

- trust over time

- resilience to new risks

- maturity in AI oversight

Without reflection, institutions:

- repeat failures

- normalise risk

- accumulate technical debt

- lose sight of why controls exist

AI governance must evolve as use evolves.

**  **

## **Apply Now â€” Key Questions**

After AI-influenced decisions, ask:

1.  **What went as expectedâ€”and what did not?**

2.  **Were governance controls proportionate?**

3.  **Did anyone raise concerns that were ignored?**

4.  **What should change in future decision processes?**

5.  **How will this learning be shared or embedded?**

Reflection must inform policy, not just memory.

## **Tool in Use â€” Governance Learning Loop**

Adopt this cycle:

**Review â†’ Adjust â†’ Reinforce**

- **One learning:** What did we discover?

- **One adjustment:** What governance rule changes?

- **One reinforcement:** What practice is reaffirmed?

Use this after major decisions or incidents.

**  **

## **Common Failure Modes in Governance**

- treating issues as one-off exceptions

- failing to update policies after incidents

- learning residing with individuals not systems

- governance drift as AI use increases

- focusing on compliance rather than capability

## **Quick Reflection**

**What governance assumption needs to be revisited next?**

**  **

# **Domains 4â€“6 in Practice (Governance & Decision-Making)**

Together, Domains 4â€“6 ensure that:

- decisions are fair, contestable, and reviewable

- AI influence remains transparent

- harm is anticipated and mitigated

- governance improves rather than ossifies

The full governance capability cycle is:

**Awareness â†’ Co-Agency â†’ Practice â†’ Ethics â†’ Governance â†’ Reflection â†’ Renewal**

Skipping steps hides risk.  
Revisiting steps builds institutional trust.

## **Stage 5 â€” Capability Self-Check, Worked Governance Scenario & Operating Model**

This final stage turns governance principles into a **repeatable decision system**.

You will:

- locate strengths and gaps in your current AI governance capability

- see how all six domains operate together in a realistic governance scenario

- leave with a **practical Governance AI Operating Model** you can reuse immediately

Nothing here is about scoring.  
Everything here is about **defensibility, consistency, and legitimacy**.

## **PART A â€” GOVERNANCE AI CAPABILITY SELF-CHECK**

This self-check answers one question:

> **â€œWhere does our governance need to tighten or adapt for AI-influenced decisions?â€**

Complete in **under five minutes**.

### **Domain 1 â€” AI Awareness & Orientation**

Ask honestly:

- We can clearly explain how AI influenced decisions

- Decision papers describe AI role in plain language

- Uncertainty and limitations are acknowledged

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If mixed/no:**
Pause approval until AI influence is clarified.

### **Domain 2 â€” Humanâ€“AI Co-Agency**

Consider:

- Decision authority is clearly named

- Accountability cannot be attributed to systems

- Committees understand their responsibility

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If unclear:**
Authority and accountability are drifting.

### **Domain 3 â€” Applied Practice & Innovation**

Reflect:

- AI is permitted where it adds value

- Controls scale with risk

- Innovation is not blocked by unnecessary bureaucracy

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If mostly no:**
Governance may be either too loose or too rigid.

### **Domain 4 â€” Ethics, Equity & Impact**

Ask:

- Affected groups are identified and considered

- Fairness and contestability are designed in

- Harms would surface early rather than late

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If mixed/no:**
Ethical risk is likely accumulating unseen.

**  **

### **Domain 5 â€” Decision-Making & Governance**

Check:

- Decisions are documented and retrievable

- Rationale is clear months later

- Escalation thresholds are understood and used

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If mixed/no:**
Defensibility is weak.

### **Domain 6 â€” Reflection, Learning & Renewal**

Finally:

- We review decision processes, not just outcomes

- Governance evolves as AI use evolves

- Lessons are embedded institutionally

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If inconsistent:**
Governance capability will stagnate.

**  **

### **Interpreting Your Self-Check**

- Gaps in **Domains 1â€“2** â†’ clarify AI influence and accountability immediately

- Gaps in **Domains 4â€“5** â†’ raise governance scrutiny before scaling

- Gaps in **Domain 6** â†’ expect repeated issues

Strong governance is **iterative, not static**.

## **PART B â€” WORKED GOVERNANCE SCENARIO (END-TO-END)**

### **Scenario**

An organisation is using AI-supported analysis to **prioritise access to limited services or resources**.  
The decision affects real people and may be challenged.

### **Domain 1 â€” Awareness in Action**

Governance requires clarity:

- AI ranks cases using selected indicators

- Not all factors (context, nuance) are captured

- Uncertainty and proxy measures exist

Decision-makers demand:

- explanation of indicators

- visibility of limitations

### **Domain 2 â€” Co-Agency in Action**

Authority is defined:

- AI informs prioritisation

- A human panel approves outcomes

- A named leader owns the final decision

No one can say, â€œThe system decided.â€

### **Domain 3 â€” Applied Practice in Action**

AI use is permitted because:

- it speeds up initial triage

- humans review borderline or high-impact cases

- governance scales with risk

Innovation existsâ€”but within guardrails.

### **Domain 4 â€” Ethics & Impact in Action**

The panel examines:

- who may be systematically deprioritised

- whether indicators disadvantage certain groups

- if appeal mechanisms are accessible

Adjustments are made before full deployment.

### **Domain 5 â€” Governance in Action**

A **Decision Defensibility Record** is created, capturing:

- AIâ€™s role

- human judgement

- mitigation steps

- review points

The organisation is prepared for challenge.

### **Domain 6 â€” Reflection in Action**

After implementation, governance reviews:

- complaints or appeals

- unintended bias

- adequacy of safeguards

Governance rules are updated accordingly.

### **What This Scenario Shows**

Good AI governance:

- does not prohibit use

- makes influence visible

- assigns responsibility clearly

- protects those affected

- enables justified decisions

Capability is shown in **process integrity**, not tool choice.

## **PART C â€” YOUR GOVERNANCE AI OPERATING MODEL**

This is your **repeatable approach** to AI-influenced decisions.

Complete once. Revisit regularly.

### **1ï¸âƒ£ Decisions Requiring Governance Oversight**

Examples:

- evaluation or eligibility

- access to services or opportunities

- resource allocation

- policy interpretation

**In our context:**

### **2ï¸âƒ£ AI Influence Boundaries**

**AI may inform:**

**AI must not determine:**

**Accountable authority:**

### **3ï¸âƒ£ Ethical & Equity Red Lines**

We pause or stop AI use when:

- 
- 

### **4ï¸âƒ£ Documentation & Escalation Triggers**

We document or escalate when:

- risk is high or irreversible

- people cannot easily contest outcomes

- decisions affect rights, safety, or reputation

### **5ï¸âƒ£ Governance Review Rhythm**

We review AI-related decisions:  
â˜ after each major decisionâ€ƒâ˜ quarterlyâ€ƒâ˜ annually

### **6ï¸âƒ£ Renewal Commitments**

To keep governance fit for purpose, we will:

- revisit thresholds as AI use scales

- update guidance after incidents

- share learning across the organisation

## **THE GOVERNANCE COMMITMENT**

> *We do not delegate accountability to systems.  
> We make AI influence visible and contestable.  
> We apply proportionate oversight.  
> We learn and adapt as risks evolve.*
