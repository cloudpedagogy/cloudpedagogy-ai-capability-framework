# **AI Capability Practice Guide: Leadership & Strategy**

**Strategic, Responsible, High-Impact AI Use for Leaders, Executives, and Decision-Makers**

## **Stage 1 â€” Orientation & Fast Start (Leadership & Strategy)**

## **Who This Guide Is For**

This guide is for people who **shape direction, priorities, and decisions** and are consideringâ€”or already usingâ€”AI to support leadership and strategy.

This includes:

- senior leaders and executives

- programme and portfolio leads

- heads of department or function

- strategy, policy, and transformation leads

- directors responsible for risk, reputation, or performance

You may not personally operate AI tools day-to-day.  
You **do** influence:

- whether AI is used

- where it is applied

- how risk is governed

- who is accountable when outcomes matter

This guide assumes **AI decisions taken at leadership level scale impact**â€”across people, budgets, systems, and public trust.

## **Who This Guide Is Not For**

This guide is **not** designed for:

- technical system design or model selection

- operational automation manuals

- prompt engineering tutorials

- delegating leadership judgement to AI outputs

- using AI to avoid accountability for decisions

If you are looking for tools that *replace* leadership responsibility rather than **support judgement**, this guide will feel intentionally restrictive.

**  **

## **What You Will Be Able to Do in 30â€“60 Minutes**

By working through this guide, you will be able to:

- decide **where AI should and should not influence strategy**

- clarify **what decisions remain human-owned** at leadership level

- identify **second-order risks** (equity, reputation, trust, governance)

- apply proportionate **oversight and escalation**

- ask better questions of teams using AI

- document decisions so they remain **defensible over time**

You will also produce at least **one tangible leadership artefact** (e.g. a decision note, boundary statement, or risk trigger list) usable immediately.

## **FAST START â€” USE THIS NOW**

If you read only one section, read this one.

This Fast Start helps leaders make **sound AI-influenced decisions** in **10 minutes**, without needing technical depth.

### **When to Use This Guide**

Use this guide when:

- AI is informing or shaping strategic options

- a recommendation feels â€œdata-drivenâ€ but opaque

- teams cite AI outputs in proposals or briefings

- you are accountable for outcomes you did not personally generate

- decisions affect people, funding, policy, or public perception

- you may need to justify decisions later to boards, auditors, or the public

If AI influences **choice, direction, or priority**, this guide applies.

## **The 10-Minute Entry Workflow (Leadership)**

Use this sequence **before** approving, rejecting, or acting on AI-influenced advice.

### **Step 1 â€” Name the Decision**

Write down, clearly:

> *â€œThis decision is about: \[specific strategic choice\].â€*

Examples:

- reallocating resources

- changing programme direction

- adopting or pausing AI use

- approving a new initiative

Vague decisions create invisible risk.

**  **

### **Step 2 â€” Identify AI Influence (Co-Agency Check)**

Ask:

- How did AI influence this recommendation?  
  (informing, ranking, forecasting, framing?)

- What assumptions might AI be embedding?

- Which judgements remain **human-owned**?

If AIâ€™s role is unclear, the decision is not ready.

### **Step 3 â€” Apply the Leadership Risk Screen**

Ask:

- If this decision is wrong, **who is affected**?

- Would the harm be reversible?

- Would I be comfortable defending this decision publicly?

If impact is wide or irreversible, slow down.

### **Step 4 â€” Decide the Governance Level**

Choose one:

âœ… **Proceed with AI-informed judgement  **
ðŸ” **Request clarification, evidence, or alternatives  **
â›” **Pause or escalate** (seek review, ethics, or board input)

Document the rationale in one paragraph.

**  **

### **Step 5 â€” Record the Decision**

Create a brief **Leadership AI Decision Note**:

- Decision made

- Role of AI

- Human judgement applied

- Risks considered

- Oversight required (if any)

This protects you and the organisation later.

## **Worked Example â€” One Decision, Three Outcomes (Leadership)**

**Decision**
Using AI-generated analysis to prioritise projects for funding.

### **âœ… Good Use**

- AI provides scenario modelling

- Leaders interrogate assumptions

- Equity and long-term impact are considered

- Final decision is human-owned and documented

**Why this works:**
AI informs strategy without displacing responsibility.

### **âš ï¸ Risky Use**

- AI ranking is largely accepted

- Assumptions go unchallenged

- Social or reputational impact is underestimated

**Why this is risky:**
Bias and long-term consequences may be baked in.

### **â›” Unacceptable Use**

- AI output is treated as â€œobjective truthâ€

- Leadership defers judgement

- No one can explain the decision later

**Why this fails:**
Accountability has been silently delegated.

## **Your First Leadership Artefact (Create This Now)**

Write a **Leadership AI Boundary Statement** (3â€“5 lines):

- Decisions AI may inform

- Decisions AI must not determine

- When escalation is required

- Who remains accountable

This single artefact prevents role drift.

## **How This Guide Works**

This guide supports **strategic judgement under pressure**.

You are not expected to apply everything every time.  
You are expected to:

- enter when AI touches leadership decisions

- apply only the relevant checks

- make accountability visible

- move forward with clarity

## **The Six Domains as a Leadership Workflow**

In leadership contexts, the six domains operate as **decision safeguards**:

- **AI Awareness & Orientation** â€” Understanding limits of AI-derived insight

- **Humanâ€“AI Co-Agency** â€” Clarifying authority and accountability

- **Applied Practice & Innovation** â€” Using AI for foresight, not automation

- **Ethics, Equity & Impact** â€” Anticipating system-level consequences

- **Decision-Making & Governance** â€” Ensuring defensibility and oversight

- **Reflection, Learning & Renewal** â€” Improving leadership capability over time

Skipping domains shifts risk onto people with less power to contest it.

**  **

## **Stage 2 â€” How This Guide Works & Situational Entry Points (Leadership & Strategy)**

## **HOW THIS GUIDE WORKS**

This guide is designed for **leaders making consequential decisions**â€”often with incomplete information, under time pressure, and with long-term implications.

You are **not** expected to read this guide end-to-end.  
You are expected to:

- enter when AI influences a leadership or strategic decision

- apply a small number of relevant checks

- make accountability explicit

- act with confidence and defensibility

This mirrors real leadership practice:  
decisions are iterative, revisited, and scrutinised after the fact.

**  **

## **The Six Domains as a Leadership Decision Framework**

The AI Capability Framework consists of six domains.  
In leadership contexts, these operate as **decision safeguards**, not technical steps.

You apply **more domains as impact, uncertainty, or risk increases**.

### **The Leadership Capability Flow**

- **AI Awareness & Orientation**
  Understand what AI-driven analysis can and cannot reliably support.

- **Humanâ€“AI Co-Agency**
  Clarify who has authority and who is accountable for decisions.

- **Applied Practice & Innovation**
  Use AI to extend foresight and option space, not to automate judgement.

- **Ethics, Equity & Impact**
  Anticipate second-order and systemic consequences.

- **Decision-Making & Governance**
  Apply proportional oversight, documentation, and escalation.

- **Reflection, Learning & Renewal**
  Improve leadership capability over time, not just decision speed.

Skipping domains does not accelerate progress.  
It shifts risk downstreamâ€”often onto people with less power to challenge outcomes.

**  **

## **Why Situational Entry Points Matter for Leaders**

Leaders rarely start with:

> â€œWhich AI capability domain applies here?â€

They start with:

- recommendations in a briefing

- dashboards or forecasts

- a proposal citing AI-generated insight

- pressure to approve or decline quickly

- reputational or political risk

Situational entry points let you respond **where the decision pressure is**, not where the framework starts.

**  **

# **SITUATIONAL ENTRY POINTS â€” START HERE**

Choose the entry point that best matches your current leadership situation.

Each one tells you:

- which domains to prioritise

- what to do immediately

- where leaders commonly fail

## **Entry Point 1 â€” â€œThe recommendation looks strong, but I donâ€™t fully trust it.â€**

AI-supported analysis is persuasiveâ€”but something feels off.

### **Primary domains to apply**

- **AI Awareness & Orientation**

- **Humanâ€“AI Co-Agency**

### **What to do now**

- Ask how the AI generated this recommendation

- Identify key assumptions and data limitations

- Confirm which judgements remain human-owned

### **Common failure mode**

- Accepting AI-produced coherence as robustness

## **Entry Point 2 â€” â€œThis decision affects people who arenâ€™t at the table.â€**

The decision will:

- affect staff, students, or communities

- change access to resources or opportunities

- set long-term direction

### **Primary domains to apply**

- **Ethics, Equity & Impact**

- **Decision-Making & Governance**

### **What to do now**

- Identify who bears the consequences

- Examine fairness, bias, or exclusion risks

- Decide whether additional oversight is required

### **Common failure mode**

- Treating indirect impact as minor

**  **

## **Entry Point 3 â€” â€œAI is influencing strategy, not just operations.â€**

AI is shaping:

- prioritisation

- resource allocation

- policy direction

- risk appetite

### **Primary domains to apply**

- **Humanâ€“AI Co-Agency**

- **Applied Practice & Innovation**

### **What to do now**

- Clarify which strategic judgements must remain human

- Use AI to explore scenarios, not dictate direction

- Request alternative framings or futures

### **Common failure mode**

- Letting AI narrow option space prematurely

**  **

## **Entry Point 4 â€” â€œIf this goes wrong, I will be accountable.â€**

You carry formal responsibility:

- to a board

- to regulators

- to the public

### **Primary domains to apply**

- **Decision-Making & Governance**

- **Ethics, Equity & Impact**

### **What to do now**

- Ensure AIâ€™s role is documented

- Check escalation and review thresholds

- Confirm alignment with organisational values and policy

### **Common failure mode**

- Assuming technical teams â€œownâ€ AI risk

**  **

## **Entry Point 5 â€” â€œWeâ€™re scaling AI use across the organisation.â€**

AI is moving from pilot to routine practice.

### **Primary domains to apply**

- **Applied Practice & Innovation**

- **Reflection, Learning & Renewal**

### **What to do now**

- Identify where AI genuinely adds strategic value

- Monitor unintended consequences

- Establish feedback and learning loops

### **Common failure mode**

- Scaling faster than governance or capability

## **Entry Point 6 â€” â€œI want to lead more effectively with AI over time.â€**

You are thinking about:

- leadership development

- organisational maturity

- future-readiness

**  **

### **Primary domains to apply**

- **Reflection, Learning & Renewal**

- **AI Awareness & Orientation**

### **What to do now**

- Review past AI-influenced decisions

- Identify patterns of over- or under-reliance

- Adjust leadership practices accordingly

### **Common failure mode**

- Treating AI capability as static

**  **

## **How the Rest of This Guide Is Structured**

From here, the guide moves into the **Core Practice Workflow**, where each domain is applied to leadership and strategy decisions.

Each domain section will:

- explain what the domain protects or enables at leadership level

- show how to apply it immediately

- identify common leadership failure modes

- include a short reflection moment

You can apply:

- one domain in isolation

- several domains for complex decisions

- or all six for high-stakes or irreversible choices

## **Stage 3 â€” Core Practice Workflow: Domains 1â€“3 (Leadership & Strategy)**

*Making Better Strategic Decisions with AI â€” Without Losing Authority or Judgment*

Domains 1â€“3 shape **how leaders engage with AI-influenced insight**.  
They prevent strategic drift, misplaced confidence, and silent delegation of authority.

Each domain follows the same canonical pattern used across the Practice Guides.

**  **

# **DOMAIN 1 â€” AI Awareness & Orientation (Strategic Literacy)**

## **What This Domain Protects**

This domain protects leaders from:

- mistaking *confidence* for *reliability*

- over-trusting forecasts, rankings, or trend analysis

- assuming AI insight is neutral, objective, or value-free

- accepting opaque recommendations without interrogating assumptions

- confusing correlation, simulation, or pattern detection with strategy

At leadership level, the risk is not technical error â€”  
it is **misplaced strategic confidence**.

AI can:

- surface options

- reveal patterns

- generate scenarios

It cannot:

- judge priorities

- weigh values

- understand organisational context

- own consequences

Awareness is what keeps leaders *in charge of direction*.

## **Apply Now â€” Key Questions**

Before acting on AI-influenced strategy or advice, ask:

1.  **What kind of insight is this actually providing?**
    (Forecast, clustering, simulation, ranking, language synthesis?)

2.  **What assumptions underpin this output?**
    (Data selection, time horizon, optimisation criteria.)

3.  **What does the AI not â€œseeâ€ here?**
    (Culture, morale, politics, equity, history.)

4.  **Where would a confident but wrong decision cause the greatest damage?**
    (People, reputation, trust, finances, long-term capability.)

If these questions feel hard to answer, pause.

## **Tool in Use â€” Strategic Awareness Check**

Use this short check before approving AI-informed recommendations:

**Strategic AI Awareness Check**

- What problem was the AI optimised to address?

- What problem does it *not* address?

- What values or priorities might be implicitly encoded?

- Where would human judgement be irreplaceable?

One sentence per question is enough.

**  **

## **Common Failure Modes in Leadership**

- deferring to AI-backed recommendations to appear â€œdata-drivenâ€

- assuming neutrality because the output is numerical or polished

- letting AI narrow strategic options too early

- underestimating reputational or human impact

- treating AI insight as a substitute for leadership judgement

## **Quick Reflection**

**Which assumptions in this recommendation deserve explicit challenge?**
Write one sentence.

**  **

# **DOMAIN 2 â€” Humanâ€“AI Co-Agency (Authority & Accountability)**

## **What This Domain Protects**

This domain protects:

- leadership authority

- clarity of accountability

- organisational trust

- decision ownership under scrutiny

In leadership contexts, **co-agency is about power and responsibility**.

AI may inform strategy.  
It must never *decide strategy*.

If leaders cannot clearly state what they decidedâ€”and whyâ€”the organisation has already lost control.

## **Apply Now â€” Key Questions**

Ask:

1.  **What parts of this decision can AI inform?**
    (Options, trade-offs, scenarios.)

2.  **What parts must remain human-owned?**
    (Prioritisation, value judgments, trade-offs.)

3.  **Who is accountable if this decision proves harmful?**
    (This should have a single, named answer.)

4.  **Could I explain this decision without referencing AI?**
    (If not, authority has drifted.)

## **Tool in Use â€” Leadership Co-Agency Map**

A rapid exercise to prevent silent delegation:

**Leadership Co-Agency Map**

- **AI informs:**

- **Humans decide:**

- **Leader accountable:**

Complete this before final approval.

## **Common Failure Modes in Leadership**

- allowing AI output to frame decisions invisibly

- citing â€œthe model saidâ€¦â€ as justification

- spreading accountability across committees

- retroactively attributing decisions to AI

- conflating consultation with delegation

These failures surface during audits, inquiries, or crises.

**  **

## **Quick Reflection**

**Could I clearly defend this decision as my own?**
Yes or no â€” and why?

# **DOMAIN 3 â€” Applied Practice & Innovation (Strategic Use Without Automation)**

## **What This Domain Enables**

This domain enables leaders to use AI to:

- explore futures and scenarios

- test assumptions

- stress-test strategies

- broaden option space

- challenge entrenched thinking

Innovation at leadership level is about **better judgement**, not faster automation.

AI should *expand thinking*, not collapse it into a single â€œoptimalâ€ path.

**  **

## **Apply Now â€” Key Questions**

Ask:

1.  **Is AI helping us think more broadly, or narrowing our view?**

2.  **Would this strategy still make sense without AI support?**

3.  **What alternative futures or interpretations should we explore?**

4.  **Are we experimenting safely, or baking assumptions into policy?**

If AI reduces debate, it is being misused.

## **Tool in Use â€” Strategic Scenario Prompt**

Use AI deliberately to expand perspective:

> *â€œGenerate three contrasting future scenarios for this decision, including risks, unintended consequences, and equity implications.  
> Do not rank or recommend.  
> We will assess suitability through human judgement.â€*

This preserves leadership agency while benefiting from AI exploration.

## **Common Failure Modes in Leadership**

- using AI to justify predetermined strategies

- locking in early AI-generated priorities

- treating forecasts as commitments

- confusing optimisation with vision

- deploying AI insight without organisational readiness

## **Quick Reflection**

**Did AI increase strategic imaginationâ€”or reduce it?**
Capture one sentence.

# **Domains 1â€“3 in Practice (Leadership & Strategy)**

Together, Domains 1â€“3 ensure that:

- AI informs rather than governs strategy

- leaders retain authority and accountability

- innovation strengthens judgment instead of replacing it

They establish the **conditions for responsible strategic leadership**.

As impact widens, these domains must be complemented by Domains 4â€“6:

- ethics

- governance

- long-term renewal

**  **

## **Stage 4 â€” Risk, Responsibility & Renewal: Domains 4â€“6 (Leadership & Strategy)**

*Governing Impact, Preserving Legitimacy, and Sustaining Leadership Capability*

Domains 4â€“6 become critical when AI-influenced decisions:

- affect peopleâ€™s livelihoods or opportunities

- shape organisational culture

- influence public perception or trust

- set precedents that others will follow

- are difficult or impossible to reverse

These domains ensure AI use at leadership level is **ethical, governed, defensible, and sustainable**.

**  **

# **DOMAIN 4 â€” Ethics, Equity & Impact (System-Level Responsibility)**

## **What This Domain Protects**

This domain protects:

- individuals and groups affected by strategic decisions

- fairness in access, opportunity, and outcomes

- organisational legitimacy and public trust

- long-term social and institutional impact

At leadership level, AI does not just affect outputs â€”  
it reshapes **systems**, **incentives**, and **power dynamics**.

Seemingly neutral AI-informed decisions can:

- entrench inequality

- marginalise certain voices

- normalise harmful trade-offs

- shift responsibility away from decision-makers

**  **

## **Apply Now â€” Key Questions**

Before finalising or scaling an AI-influenced decision, ask:

1.  **Who benefits from this decisionâ€”and who does not?**

2.  **Which groups bear disproportionate risk or cost?**

3.  **Does AI amplify existing inequalities or biases?**

4.  **What values are implicitly prioritised (e.g. efficiency over fairness)?**

5.  **What harm would be hardest to reverse?**

These questions are governance, not politics.

## **Tool in Use â€” Strategic Ethical Impact Scan**

Use this brief scan on any strategic AI use:

**Ethical Impact Scan (Leadership)**

- **Fairness risk:** Who may be disadvantaged?

- **Bias risk:** What patterns may be reinforced?

- **Power risk:** Who loses the ability to contest decisions?

- **Reversal risk:** What consequences cannot easily be undone?

Capture one sentence per risk.

**  **

## **Common Failure Modes in Leadership**

- treating ethical issues as downstream compliance checks

- assuming aggregated data eliminates bias

- dismissing equity concerns as â€œout of scopeâ€

- focusing on intent rather than impact

- normalising harmful trade-offs through repetition

## **Quick Reflection**

**Whose perspective is most absent from this decisionâ€”and why?**

**  **

# **DOMAIN 5 â€” Decision-Making & Governance (Organisational Accountability)**

## **What This Domain Protects**

This domain protects:

- clarity of authority and accountability

- organisational coherence

- auditability and transparency

- trust with regulators, boards, staff, and the public

- institutional memory over time

Governance ensures AI does not quietly reshape decisions without oversight.

At leadership level, governance answers:

> *â€œWho decided what, why, and with which safeguards?â€*

## **Apply Now â€” Key Questions**

Before approving or delegating an AI-influenced decision, ask:

1.  **Where does this decision sit in our risk hierarchy?**

2.  **What documentation is proportionate and necessary?**

3.  **Who must review or be consulted?**

4.  **How will this decision be explained externally if needed?**

5.  **Are governance mechanisms keeping pace with adoption?**

If governance lags adoption, risk compounds.

## **Tool in Use â€” Leadership Decision Transparency Note**

For any consequential AI-influenced decision, record:

**Leadership Decision Transparency Note**

- **Decision:**

- **Purpose:**

- **Role of AI:** inform / analyse / scenario-model

- **Human judgement applied:**

- **Risks considered:**

- **Oversight or escalation:**

This need not be lengthy.  
It must be **clear and retrievable**.

## **Governance Triggers (Leadership Context)**

Additional review or escalation is required when AI influences:

- workforce or student evaluation

- resource allocation or restructuring

- access to opportunities or services

- policy or compliance interpretation

- public communications or reputation

- safety-critical or legally sensitive decisions

When in doubt: **slow the decision, not the process**.

## **Common Failure Modes in Leadership**

- assuming governance is a technical or legal problem

- delegating AI oversight without authority

- inconsistent documentation across teams

- informal decision-making becoming precedent

- governance that exists on paper but not in practice

## **Quick Reflection**

**Could this decision withstand scrutiny from those most affected?**

**  **

# **DOMAIN 6 â€” Reflection, Learning & Renewal (Strategic Maturity)**

## **What This Domain Sustains**

This domain sustains:

- leadership judgement over time

- organisational learning

- adaptive capability

- trust and legitimacy

- resilience against hype and complacency

AI capability is not static.  
Neither is strategic risk.

Without reflection, organisations:

- repeat the same mistakes

- scale unexamined assumptions

- mistake speed for progress

**  **

## **Apply Now â€” Key Questions**

After meaningful AI-influenced decisions, ask:

1.  **Did AI improve the quality of judgement or just the speed?**

2.  **What unintended consequences emerged?**

3.  **Where did leadership over- or under-trust AI?**

4.  **What should change in future decision processes?**

5.  **How will we capture and share this learning?**

## **Tool in Use â€” Leadership Reflection Loop**

Adopt a simple cycle:

**Reflect â†’ Adjust â†’ Reapply**

- **One insight:** What did we learn?

- **One adjustment:** What will change next time?

- **One boundary:** What AI influence will be limited?

This can be discussed in minutes during leadership meetings.

**  **

## **Common Failure Modes in Leadership**

- reviewing outcomes but not decision processes

- learning staying with individuals, not systems

- treating AI capability as â€œsolvedâ€ once adopted

- ignoring weak signals until harm occurs

## **Quick Reflection**

**What assumption about AI leadership just changed for me?**

**  **

# **Domains 4â€“6 in Practice (Leadership & Strategy)**

Together, these domains ensure that:

- leadership decisions remain humane and legitimate

- AI use is transparent and contestable

- accountability is not displaced

- organisational learning compounds over time

The complete leadership capability cycle is:

**Awareness â†’ Co-Agency â†’ Practice â†’ Ethics â†’ Governance â†’ Reflection â†’ Renewal**

Skipping steps hides risk.  
Revisiting steps builds leadership maturity.

## **Stage 5 â€” Capability Self-Check, Worked Leadership Scenario & Operating Model**

This final stage turns leadership intent into a **repeatable system**.

You will:

- identify where your leadership AI capability is strongest and weakest

- see how all six domains work together in a high-stakes leadership scenario

- leave with a **Leadership AI Operating Model** you can use immediately

Nothing here is evaluative.  
Everything here is **action-oriented**.

## **PART A â€” LEADERSHIP AI CAPABILITY SELF-CHECK**

This is **not a test** and **not a scorecard**.  
It answers one question:

> **â€œWhere should I focus next to lead responsibly with AI?â€**

Complete in **under five minutes**.

### **Domain 1 â€” AI Awareness & Orientation**

Ask yourself:

- I understand what AI analysis can and cannot reliably provide

- I challenge assumptions behind AI-informed recommendations

- I do not mistake confidence or numbers for correctness

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If mixed/no:**
Pause high-impact use until assumptions are surfaced.

### **Domain 2 â€” Humanâ€“AI Co-Agency**

Consider:

- I explicitly define what AI informs vs what humans decide

- Accountability for decisions is clear and named

- I could explain decisions without referencing AI

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If unclear:**
Authority and accountability are drifting.

### **Domain 3 â€” Applied Practice & Innovation**

Reflect:

- AI is used to expand options, not collapse them

- We explore alternatives rather than optimise prematurely

- We can imagine sound strategy without AI

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If mostly no:**
AI may be constraining strategic imagination.

### **Domain 4 â€” Ethics, Equity & Impact**

Ask:

- We consider who benefits and who bears risk

- Equity and representation are explicitly examined

- We pause when harms would be hard to reverse

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If mixed/no:**
Ethics must move earlier in leadership decisions.

### **Domain 5 â€” Decision-Making & Governance**

Check:

- AI influence on decisions is documented proportionately

- Review and escalation thresholds are understood

- Decisions would withstand internal or public scrutiny

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If mixed/no:**
Governance is lagging adoption.

### **Domain 6 â€” Reflection, Learning & Renewal**

Finally:

- We review how decisions were made, not just outcomes

- Lessons from AI use are shared and embedded

- Boundaries are updated as risks evolve

â˜ Mostly yesâ€ƒâ€ƒâ˜ Mixedâ€ƒâ€ƒâ˜ Mostly no

**If inconsistent:**
Capability will stagnate.

### **Interpreting Your Self-Check**

- Gaps in **Domains 1â€“2** â†’ rebuild leadership foundations

- Gaps in **Domains 4â€“5** â†’ increase oversight before scaling

- Gaps in **Domain 6** â†’ learning is not compounding

Leadership capability grows by **rebalancing**, not maximising.

**  **

## **PART B â€” WORKED LEADERSHIP SCENARIO (END-TO-END)**

### **Scenario**

You are deciding whether to **scale AI use across an organisation** based on AI-informed pilot results.  
The decision affects staff roles, budgets, reputation, and long-term direction.

### **Domain 1 â€” Awareness in Action**

You recognise:

- AI performance metrics reflect what was measured

- Unmeasured impacts (culture, trust, equity) remain invisible

You therefore:

- ask what success indicators were excluded

- interrogate assumptions behind forecasts

### **Domain 2 â€” Co-Agency in Action**

You clarify:

- AI informs scenario modelling

- Leadership owns prioritisation and trade-offs

- Accountability rests with named leaders

This prevents post-hoc deflection.

### **Domain 3 â€” Applied Practice in Action**

You:

- explore multiple scaling options (full, phased, paused)

- ask AI for contrasting futures rather than recommendations

- keep strategic judgement human-led

AI expands thinking; it does not dictate direction.

### **Domain 4 â€” Ethics & Impact in Action**

You examine:

- effects on job security and workload

- who benefits first vs who absorbs disruption

- whether vulnerable groups are disproportionately affected

You adjust pace and safeguards accordingly.

### **Domain 5 â€” Governance in Action**

You create a **Leadership Decision Transparency Note** documenting:

- role of AI analysis

- human judgements applied

- risks considered

- review points after implementation

The decision becomes defensible over time.

### **Domain 6 â€” Reflection in Action**

After implementation, you ask:

- Did AI improve judgementâ€”or just accelerate it?

- What unintended consequences appeared?

- What governance should tighten next cycle?

Learning feeds forward.

### **What This Scenario Shows**

Responsible leadership with AI:

- preserves authority

- makes value judgements explicit

- anticipates second-order effects

- builds trust through transparency

Capability is visible in **how** decisions were made.

**  **

## **PART C â€” YOUR LEADERSHIP AI OPERATING MODEL**

This is your **personal or organisational system** for leading with AI.

Complete once. Revisit regularly.

### **1ï¸âƒ£ Valid Reasons We Use AI in Leadership**

Examples:

- scenario exploration

- stress-testing assumptions

- surfacing risks

- supporting long-term foresight

**Our reasons:**

### **2ï¸âƒ£ Leadership Co-Agency Rules**

**AI may inform:**

**AI may not decide:**

**Ultimate accountability rests with:**

### **3ï¸âƒ£ Ethical Red Lines**

We pause or stop AI-influenced decisions when:

- 
- 

### **4ï¸âƒ£ Governance Triggers**

We document or escalate when AI affects:

- people or livelihoods

- access or opportunity

- policy or reputation

- long-term strategy

### **5ï¸âƒ£ Reflection Rhythm**

After key decisions, we ask:

- What improved?

- What risk emerged?

- What should change next time?

Reflection cadence:  
â˜ after major decisionsâ€ƒâ˜ quarterlyâ€ƒâ˜ annually

### **6ï¸âƒ£ Renewal Commitments**

To keep leadership capability current, we will:

- revisit assumptions regularly

- adjust boundaries as tools evolve

- share learning openly

## **THE LEADERSHIP COMMITMENT**

> *We use AI to informâ€”not replaceâ€”leadership judgement.  
> We retain authority, accountability, and responsibility.  
> We make decisions transparent and contestable.  
> We reflect so capability compounds over time.*
