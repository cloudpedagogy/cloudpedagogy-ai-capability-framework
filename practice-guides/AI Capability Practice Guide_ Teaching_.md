# **AI Capability Practice Guide: Teaching**

**Practical, Responsible, High-Impact AI Use for Educators and Learning Designers**

## **Who This Guide Is For**

This guide is for educators who want to use AI responsibly and creatively in:

- teaching preparation

- curriculum design

- assessment creation

- feedback and communication

- student support

- academic leadership

It is designed for:

- lecturers

- tutors

- module and programme convenors

- learning designers

- teaching fellows

- academic developers

You do **not** need technical AI expertise.  
You *do* need to make decisions that affect students, their learning, and academic standards.

## **Who This Guide Is *Not* For**

This guide is not intended to support:

- automated grading or marking-offloading

- removing educator judgement

- replacing teaching presence

- delegating curriculum decisions to AI

- “speed-first” approaches that compromise academic integrity

If you seek shortcuts that reduce professional responsibility, this guide will feel intentionally restrictive.

## **What You Will Be Able to Do in 30–60 Minutes**

By engaging with this guide, you will be able to:

- decide when AI is pedagogically appropriate — and when it is not

- design clear educator–AI–student role boundaries

- create teaching materials with integrity and clarity

- anticipate student risks (equity, access, misunderstanding, over-reliance)

- design and review assessment with AI-awareness

- document teaching decisions transparently

- adjust your practice as AI evolves

You will also produce at least one **teaching artefact** (e.g., a revised assessment, lesson plan, or AI-use note) ready for immediate use.

# **FAST START — USE THIS NOW**

> This Fast Start is designed so that an educator can act responsibly with AI in **under 10 minutes**.

## **When to Use This Guide**

Use this guide when:

- designing or updating a lecture, workshop, or online resource

- drafting assessment questions, criteria, or exemplars

- generating feedback or explanations for students

- creating course documentation or learning support

- anticipating how students might use AI (productively or problematically)

- supporting colleagues in AI adoption

- being asked to justify teaching decisions involving AI

If academic integrity, student learning, or fairness could be affected, this guide is essential.

**  **

## **The 10-Minute Teaching Workflow**

Use this sequence before using AI in teaching or assessment.

### **Step 1 — Identify the Teaching Purpose**

State clearly:

> “I am using AI to support: **\[learning purpose\]**”

Examples:

- clarifying complex concepts

- drafting initial materials

- generating examples

- widening perspectives

- modelling thinking

Avoid:

- outsourcing disciplinary judgement

- replacing student practice

- generating assessments without supervision

**  **

### **Step 2 — Define Educator–AI–Student Roles**

Use this 3-part teaching-specific co-agency check:

1.  **AI supports me by…**

2.  **Students may use AI to…**

3.  **I remain responsible for…**

If educator and student boundaries blur, pause — learning integrity is at risk.

### **Step 3 — Apply the Pedagogical Sanity Check**

Before generating or using AI output, ask:

- Does this strengthen learning?

- Does this reduce opportunities for student practice?

- Does this risk cognitive offloading for students?

- Would clarity or difficulty be distorted?

If learning is weakened, do not proceed.

**  **

### **Step 4 — Run the Academic Integrity & Fairness Screen**

Ask:

- Is this creating unfair advantage?

- Could this mislead students about expectations?

- Am I introducing unseen bias into learning materials?

- Will students know what is acceptable?

If the answer to any is uncertain, revise.

### **Step 5 — Make the Teaching Decision**

Choose one:

- **Proceed carefully**
  (with review, disclosure, or adaptation)

- **Revise the task or prompt**

- **Pause and escalate**
  (assessment boards, QA, module lead, digital education team)

Document your reasoning — academic integrity requires traceability.

**  **

## **Worked Example: Same Teaching Task, Three Outcomes**

### **Teaching Task**

Preparing a reading guide for a complex topic using AI.

### **✅ Good Use**

- AI drafts an outline

- Educator reviews for accuracy and level

- Misleading or overly confident statements are removed

- Student misconceptions are anticipated and addressed

**Why this works:**
AI accelerates structure, but *pedagogical judgement* shapes learning.

### **⚠️ Risky Use**

- AI produces a guide

- Educator edits lightly

- Level and language drift away from expected learning outcomes

**Why this is risky:**
Students may be misdirected or miscalibrated about difficulty.

**  **

### **⛔ Unacceptable Use**

- AI-generated guide is posted as-is

- No check for conceptual accuracy or bias

- No transparency to students

**Why this fails:**
It breaches academic duty of care and undermines disciplinary integrity.

## **Your First Teaching Artefact**

Create an **AI-Use Teaching Note** for the task you are working on:

> *Teaching task:  *
> *Why AI is being used:  *
> *Educator–AI–student roles:  *
> *Integrity or fairness risks considered:  *
> *Decision made:*

This note helps:

- justify decisions to boards, audits, or colleagues

- build consistency across modules

- improve future teaching design

**  **

# **STAGE 2 — AI CAPABILITY IN TEACHING PRACTICE**

## **How the Six Domains Work *Differently* for Educators**

Teaching with AI is **not** individual AI use at scale.  
It is a **professional practice with downstream consequences**.

Every decision you make:

- shapes how students learn

- signals what counts as knowledge

- redistributes effort, advantage, and risk

This stage shows how each AI Capability domain **behaves differently in teaching contexts**.

## **The Teaching Capability Lens (Important Shift)**

In teaching:

- mistakes scale to *many students*

- ambiguity confuses learning trajectories

- hidden AI use undermines trust

- unclear boundaries distort assessment

Therefore:

> **Teaching capability must be more explicit, documented, and anticipatory** than individual practice.

## **Domain 1 — Awareness & Orientation (Teaching-Specific)**

### **What This Domain Means in Teaching**

Educator awareness is not just AI literacy.

It includes:

- understanding how AI explanations *shape student mental models*

- recognising when AI oversimplifies disciplinary thinking

- anticipating common misunderstandings created by AI-generated material

### **Teaching-Specific Risks**

- AI presents *answers* without modelling *reasoning*

- Concepts appear simpler than they are

- Uncertainty is smoothed away

- Disciplinary norms are misrepresented

These risks directly affect learning quality.

### **Apply Now — Awareness Check for Teaching**

Before using AI-generated teaching material, ask:

- What thinking process does this *model* for students?

- What disciplinary judgement is missing?

- Where might students over-trust this explanation?

If you cannot answer, revise before use.

### **Teaching Failure Mode**

> “It sounded clear, so I used it.”

Clarity without epistemic care erodes learning.

## **Domain 2 — Human–AI Co-Agency (Teaching-Specific)**

### **What This Domain Means in Teaching**

Teaching co-agency is **triadic**:

**Educator ↔ AI ↔ Student**

Each must have clearly differentiated roles.

### **Required Role Boundaries**

> **AI may support educators by:**

- drafting outlines or examples

- generating alternative explanations

- assisting feedback phrasing

> **AI may support students by:**

- brainstorming

- language support

- self-checking understanding

> **AI must not:**

- determine grades

- replace student thinking

- obscure authorship or responsibility

### **Apply Now — Co-Agency Mapping (Teaching)**

Complete this for any AI-influenced task:

- Where does educator judgement enter?

- Where must students struggle productively?

- Where does AI assist *without displacing* learning?

If AI erodes productive struggle, redesign the task.

### **Teaching Failure Mode**

> “Students will use AI anyway, so it doesn’t matter.”

This abdicates pedagogical responsibility rather than designing for reality.

**  **

## **Domain 3 — Applied Practice & Innovation (Teaching-Specific)**

### **What This Domain Means in Teaching**

Innovation in teaching with AI is **pedagogical design**, not technical novelty.

It involves:

- redesigning learning tasks

- changing assessment focus

- modelling ethical AI use explicitly

### **High-Value Teaching Uses**

- generating multiple examples or counterexamples

- simulating stakeholder perspectives

- modelling analytical critique of AI outputs

- supporting inclusive access (language, structure, pacing)

### **Apply Now — Innovation Check**

Ask:

- Does this use make learning *richer*, not easier?

- Does it surface thinking, not conceal it?

- Does it reward reasoning over outputs?

If innovation only increases speed, reconsider.

### **Teaching Failure Mode**

> “I used AI to save time, but learning stayed the same.”

Innovation that does not improve learning is misdirected efficiency.

## **Domain 4 — Ethics, Equity & Impact (Teaching-Specific)**

### **What This Domain Means in Teaching**

Teaching ethics is about:

- fairness

- access

- representation

- assessment justice

AI intensifies existing inequities unless designed otherwise.

### **Teaching-Specific Risks**

- language advantages for some students

- hidden norms embedded in AI outputs

- disadvantaging students unfamiliar with AI tools

- reinforcing dominant perspectives

**  **

### **Apply Now — Equity Check for Teaching**

Before releasing materials or assessments, ask:

- Who is advantaged by this design?

- Who may be excluded or misrepresented?

- Are expectations explicit and transparent?

Ethical teaching requires anticipatory design.

### **Teaching Failure Mode**

> “We didn’t intend inequity.”

Impact outweighs intention.

## **Domain 5 — Decision-Making & Governance (Teaching-Specific)**

### **What This Domain Means in Teaching**

Teaching governance ensures:

- assessment integrity

- transparency

- defendable academic decisions

It is not bureaucracy — it is professional protection.

**  **

### **Teaching Decisions That Require Governance**

- assessment design

- marking or feedback practices

- AI guidance to students

- curriculum-level changes

For these:

- AI use must be explainable

- roles must be documented

- escalation pathways must exist

### **Apply Now — Teaching Governance Log (Minimal)**

For high-impact teaching decisions:

> **Teaching Governance Note**

- Decision affected:

- Role of AI:

- Human oversight applied:

- Risks considered:

A short record is sufficient — silence is not.

**  **

### **Teaching Failure Mode**

> “No one asked, so I didn’t document it.”

Governance exists *before* challenge, not after.

## **Domain 6 — Reflection, Learning & Renewal (Teaching-Specific)**

### **What This Domain Means in Teaching**

Reflection is not personal rumination.

It is:

- pedagogical evidence

- curriculum learning

- quality enhancement

### **Apply Now — Teaching Reflection Prompts**

After using AI in teaching, ask:

- Did this change how students engaged?

- What misconceptions appeared?

- What should be adjusted next time?

Share insights with colleagues — capability scales socially.

### **Teaching Failure Mode**

> “It seemed fine at the time.”

Unexamined success can embed long-term harm.

## **The Teaching Capability Pattern (Summary)**

Teaching with AI requires:

- **clear boundaries**

- **designed struggle**

- **explicit expectations**

- **documented judgement**

- **iterative refinement**

It is *not* about tool mastery.  
It is about professional responsibility in an AI-rich learning environment.

**  **

# **STAGE 3 — APPLIED AI WORKFLOWS FOR TEACHING**

## **Designing Learning, Assessment, and Feedback with AI Present**

This stage answers one core question:

> **“How do I actually teach well when AI is part of the learning environment?”**

The focus here is *pedagogical design*, not personal productivity.

## **Teaching Reality Check (Important)**

In teaching:

- outputs affect learners’ understanding, not just efficiency

- design decisions shape what students practice

- poor AI design teaches the *wrong habits*

Therefore:

> **Every AI use in teaching is a curriculum decision.**

**  **

## **Workflow 1 — Designing Teaching Materials with AI**

### **Appropriate Uses**

AI can support educators by:

- generating alternative explanations

- suggesting examples or analogies

- drafting outlines or activities

- adapting materials for different levels

### **Teaching Workflow (Material Design)**

1.  **Define the learning intent**

    - What must students understand or practise?

2.  **Use AI for variation, not authority**

    - Ask for multiple explanations, not “the best one.”

3.  **Apply disciplinary judgement**

    - Remove inaccuracies, oversimplifications, or tonal drift.

4.  **Reinsert epistemic cues**

    - Add uncertainty, assumptions, and limits explicitly.

5.  **Align with assessment**

    - Ensure materials support, not shortcut, learning outcomes.

**  **

### **Good Practice Example**

AI generates three alternative explanations of a difficult concept.  
The educator selects one, rewrites parts, and adds a warning about common misconceptions.

### **Poor Practice Example**

AI explanation is posted directly to the learning platform as “support material.”

## **Workflow 2 — Assessment Design in an AI-Rich Environment**

### **The Core Shift**

Assessment can no longer rely on:

- polished prose

- generic synthesis

- easily reproducible outputs

AI changes *what evidence of learning looks like*.

### **High-Integrity Assessment Principles**

Design assessments that:

- require judgement, context, or justification

- make reasoning visible

- include reflective or process elements

- differentiate between support and substitution

### **Teaching Workflow (Assessment Design)**

1.  **Identify what must be human**

    - What cannot be meaningfully delegated to AI?

2.  **Anticipate AI use**

    - Assume students will attempt to use AI.

3.  **Design for transparency**

    - Require declaration or commentary where appropriate.

4.  **Shift emphasis**

    - From product → process, critique, or application.

5.  **Document the decision**

    - Capture the rationale for audit or review.

**  **

### **Good Practice Example**

Students submit:

- a short output

- a reflective note explaining how AI was used (or not)

- a justification of final decisions

### **Poor Practice Example**

Assessment remains unchanged but enforcement relies solely on detection.

## **Workflow 3 — Feedback and Student Communication**

### **Why Feedback Is High Risk**

AI-generated feedback:

- shapes student confidence

- influences effort and identity

- can unintentionally bias or demotivate

Feedback requires **relational judgement**, not generic phrasing.

**  **

### **Teaching Workflow (Feedback Design)**

1.  **Decide what feedback is for**

    - Improvement, reassurance, direction, challenge?

2.  **Use AI as a drafting partner**

    - Tone, clarity, structure — not judgement.

3.  **Review for bias and framing**

    - Especially for students at the margins.

4.  **Personalise deliberately**

    - Ensure feedback signals human attention.

### **Good Practice Example**

AI helps draft concise, neutral phrasing.  
Educator adjusts emphasis, removes assumptions, and adds personalised comments.

### **Poor Practice Example**

Bulk AI-generated feedback sent without review.

**  **

## **Workflow 4 — Student Guidance on Acceptable AI Use**

### **Teaching Responsibility**

If students do not know what is acceptable, **they will infer it**.

Silence ≠ neutrality.

### **Teaching Workflow (Student AI Guidance)**

1.  **Be explicit**

    - What AI use is acceptable, limited, or prohibited?

2.  **Link to learning goals**

    - Explain *why* the boundaries exist.

3.  **Model ethical use**

    - Show examples of critique, not just generation.

4.  **Revisit regularly**

    - Guidance must evolve with tasks.

### **Good Practice Example**

Students are shown:

- a weak AI-generated answer

- a critical review of it

- a revised, human-led response

### **Poor Practice Example**

Generic policy statement with no task-level guidance.

## **Workflow 5 — Supporting Colleagues and Programmes**

Teaching capability is collective.

AI use spreads informally unless shaped intentionally.

### **Programme-Level Teaching Practices**

- share AI-use notes

- align expectations across modules

- document agreed boundaries

- surface risks early

This prevents inconsistent student experience.

### **Teaching Failure Pattern**

> “Everyone is doing something different.”

This creates confusion, unfairness, and governance risk.

**  **

## **Teaching Capability Signals (Self-Check)**

You are teaching well with AI if:

- students still struggle productively

- reasoning is visible in assessment

- expectations are explicit

- decisions can be explained

- learning improves, not just delivery speed

**  **

# **STAGE 4 — ETHICS, EQUITY, GOVERNANCE & PEDAGOGICAL RENEWAL**

## **Designing Teaching That Remains Fair, Transparent, and Defensible in an AI World**

AI introduces powerful teaching opportunities — but also substantial **ethical, equity, and integrity risks**.  
In education, **impact is multiplied**: one decision affects dozens, hundreds, or thousands of learners.

This stage turns domains 4–6 of the AI Capability Framework into **teaching-specific safeguards and renewal mechanisms**.

**  **

# **DOMAIN 4 — ETHICS, EQUITY & IMPACT IN TEACHING**

## **AI changes *who benefits* and *who is disadvantaged* in learning.**

Ethical teaching requires **anticipation**, not reaction.

## **1. Ethics as a Teaching Design Constraint**

In teaching, ethics is not optional reflection. It is a **professional requirement** that influences:

- what examples you choose

- how you explain concepts

- how accessible your materials are

- which students are unintentionally marginalised

- how assessment opportunities are distributed

AI amplifies these risks because it:

- reinforces common or dominant patterns

- erases minority perspectives

- generates confident but biased explanations

- homogenises tone and cultural reference points

Educators must intervene *before* these outputs reach learners.

**  **

## **2. Key Ethical Risks in Teaching with AI**

### **A. Epistemic Distortion**

AI often simplifies complex disciplinary ideas into:

- overly certain explanations

- generic patterns

- missing nuance

This mis-teaches the discipline.

### **B. Equity Gaps**

AI may unintentionally:

- favour students with stronger digital literacy

- reinforce stereotypes

- present Western, anglophone framings as universal

These inequities become *learning inequities*.

### **C. Hidden Labour Displacement**

If feedback or teaching materials are AI-produced with little human oversight:

- students experience less teacher presence

- relational belonging weakens

- trust in the programme declines

### **D. Assessment Justice**

AI-generated exemplars or unclear boundaries can:

- advantage confident AI users

- disadvantage students who avoid AI due to integrity concerns

- create mismatches between teaching and marking standards

## **3. Ethics Application Tool — The Teaching Impact Scan**

Use this **before** sharing AI-influenced materials or assessments:

> **TEACHING IMPACT SCAN**

- Whose voice or perspective might be missing?

- Could this explanation misrepresent the discipline?

- Who gains advantage from this design?

- Who might be harmed, confused, or misled?

- What expectations are implicitly communicated to learners?

If any answer signals risk → revise, contextualise, or add human commentary.

**  **

# **DOMAIN 5 — DECISION-MAKING & GOVERNANCE IN TEACHING**

## **Teaching decisions influenced by AI must be transparent, explainable, and defendable.**

Educational governance is not bureaucracy — it is:

- protection for students

- protection for educators

- protection for institutional integrity

## **1. Why Governance Matters More in Teaching Than in Individual Practice**

Teaching involves:

- accountability to boards and QA structures

- formal scrutiny (moderation, external examiners)

- public and regulatory expectations

- unequal power dynamics with students

Therefore:

> **If AI influences teaching or assessment, a governance trail must exist.**

**  **

## **2. When Governance Is Required**

Governance is required when AI influences:

### **A. Assessment Design**

- question generation

- reweighting of criteria

- exemplars or marking guides

- assessment format changes

### **B. Teaching Materials**

- core explanations

- topic summaries

- diagrams or “authoritative” content

- reading guides or lecture notes

### **C. Student-Facing Communications**

- feedback

- progression advice

- policy interpretation

- responses that imply decisions

### **D. Programme-Level Decisions**

- module descriptions

- intended learning outcomes

- curriculum mapping

These contexts require:

- documented reasoning

- review by colleagues or committees

- clear declarations if AI assisted

## **3. Teaching Governance Tool — The Transparent Teaching Note**

For any high-impact teaching decision:

> **TEACHING GOVERNANCE NOTE**

- Decision area (assessment, teaching material, student guidance, etc.)

- How AI contributed (draft, option generation, language support)

- Human judgement applied (validation, rewriting, rethinking)

- Risks considered (equity, integrity, misunderstanding)

- Outcome (proceed, revise, escalate)

- Oversight required? (yes/no — and by whom)

This protects you from:

- formal complaints

- integrity challenges

- student appeals

- external examiner scrutiny

## **4. Escalation Conditions**

Escalate to programme leadership, assessment boards, or QA teams when:

- AI changes meaning or difficulty of assessment

- AI may introduce bias affecting student subgroups

- AI materially shapes a teaching decision with consequences

- Uncertainty remains after review

- Colleagues disagree about AI’s role

Teaching-related risk must never be carried alone.

**  **

# **DOMAIN 6 — REFLECTION, LEARNING & RENEWAL (PEDAGOGICAL ADVANCEMENT)**

## **Teaching capability evolves through cycles of use, evidence, and improvement.**

Reflection is not personal introspection.  
It is **pedagogical inquiry.**

The goal is not:

> “Did this AI use work for me?”

But:

> “Did this AI use support or distort learning?”

## **1. Teaching Reflection Prompts**

After using AI in teaching, ask:

### **Learning Impact**

- Did students engage differently with the material?

- Did misunderstandings increase or decrease?

- Did students rely on AI more than intended?

### **Assessment Integrity**

- Did expectations remain clear?

- Did student outputs reveal gaps or over-reliance?

### **Equity & Access**

- Who benefited most?

- Who faced new barriers?

- Did any group become disadvantaged unintentionally?

### **Future Adjustment**

- What should be changed in the next cycle?

- What boundaries should be clarified?

- What evidence do I need to gather next time?

## **2. Teaching Renewal Practices**

Renewal strengthens departmental and institutional capability.

Effective practices:

- sharing revised assessments and boundaries

- aligning expectations across modules

- co-developing discipline-specific guidance

- gathering student perspectives on AI use

- reviewing examples of good and problematic AI use

Reflection becomes professional knowledge, not private insight.

**  **

## **3. Indicators of Mature Teaching Capability**

You know your teaching capability has matured when:

- AI use **strengthens** learning outcomes, not shortcuts them

- assessments still surface **student thinking**

- teaching materials model **disciplinary reasoning**

- expectations are explicit and unambiguous

- governance documentation becomes routine, not reactive

- students feel **supported**, not confused

- colleagues share a common AI use language

# **The Teaching Responsibility Principle**

> **Students should learn *better*, think *better*, and act *more responsibly* because AI is present — not despite it.**

This principle anchors ethical and pedagogical responsibility across all teaching decisions.

**  **

# **STAGE 5 — TEACHING CAPABILITY SELF-CHECK, WORKED SCENARIO & OPERATING MODEL**

## **From Responsible Intention to Defensible Teaching Practice**

## **PART A — TEACHING AI CAPABILITY SELF-CHECK**

This is **not** an evaluation and **not** a compliance tool.  
It is a **rapid orientation instrument** to help educators decide **where to focus next**.

Complete in 5–7 minutes.

### **Domain 1 — Awareness & Orientation (Teaching)**

✔ I can identify where AI explanations oversimplify disciplinary thinking  
✔ I understand how AI outputs may reshape student mental models  
✔ I recognise where AI fluency can mask conceptual gaps

**If gaps exist:**
Pause AI use in core teaching materials and revise explanations.

### **Domain 2 — Educator–AI–Student Co-Agency**

✔ I explicitly design boundaries between educator, AI, and student roles  
✔ I make expectations visible to students  
✔ I avoid delegating judgement to AI

**If unclear:**
Re-design tasks before further AI integration.

### **Domain 3 — Applied Teaching & Innovation**

✔ AI use strengthens learning rather than reduces struggle  
✔ I use AI to reveal thinking, not hide it  
✔ I test pedagogical impact rather than assume value

**If weak:**
Shift innovation from content generation to learning design.

### **Domain 4 — Ethics, Equity & Impact**

✔ I anticipate unequal access or advantage  
✔ I consider representation and framing  
✔ I design for transparency and fairness

**If uncertain:**
Run the Teaching Impact Scan before material release.

### **Domain 5 — Decision-Making & Governance**

✔ I document high-impact AI teaching decisions  
✔ I can explain AI influence if challenged  
✔ I know when escalation is required

**If missing:**
Implement the Teaching Governance Note immediately.

**  **

### **Domain 6 — Reflection & Pedagogical Renewal**

✔ I review AI impact on learning outcomes  
✔ I adapt tasks and guidance based on evidence  
✔ I share learning with colleagues

**If inconsistent:**
Introduce a simple reflection cadence at module end.

### **Interpreting Your Results**

- Early-domain gaps → **slow down and clarify foundations**

- Ethics or governance gaps → **increase oversight before scaling**

- Reflection gaps → **capability will stall without renewal**

Teaching capability grows through *alignment*, not acceleration.

**  **

## **PART B — WORKED SCENARIO: END-TO-END TEACHING PRACTICE**

This scenario mirrors **routine but high-stakes teaching reality**.

### **Scenario**

You are revising a **take-home assessment** in a module where students are actively using generative AI.  
You must ensure integrity, fairness, and learning value.

### **Domain 1 — Awareness in Action**

You recognise:

- AI can draft plausible answers quickly

- Surface-level synthesis is no longer valid evidence of learning

**Design implication:**
Assessment must require reasoning, not just output.

### **Domain 2 — Co-Agency in Action**

You define roles:

> **Students may use AI to:**

- brainstorm ideas

- clarify understanding

> **Students may not use AI to:**

- generate final submissions without attribution

- replace analytical reasoning

> **Educator remains responsible for:**

- assessment design

- marking standards

- fairness enforcement

These boundaries are documented and communicated.

### **Domain 3 — Applied Teaching & Innovation**

You redesign the task to include:

- a short analytical output

- a justification of reasoning

- a reflective commentary on AI use (or non-use)

Learning evidence becomes visible.

### **Domain 4 — Ethics & Equity in Action**

You consider:

- students unfamiliar with AI

- accessibility differences

- linguistic advantage

You:

- provide examples of acceptable AI use

- clarify expectations explicitly

- avoid penalising ethical restraint

### **Domain 5 — Governance in Action**

You create a **Teaching Governance Note**:

- AI influenced task redesign

- Human judgement applied

- Equity risks considered

This protects assessment defensibility.

### **Domain 6 — Reflection in Action**

After marking, you review:

- patterns of misunderstanding

- over-reliance on AI

- uneven performance across groups

You adjust guidance for next iteration.

**  **

### **What This Scenario Demonstrates**

Good teaching with AI:

- redesigns assessment first

- documents judgement

- makes learning explicit

- improves future practice

## **PART C — TEACHING PRACTICE OPERATING MODEL**

## **Your Repeatable Teaching System**

This model turns principles into habit.

### **1️⃣ My Teaching-Appropriate AI Uses**

Examples:

- generating alternative explanations

- drafting feedback structure

- creating counter-examples

Write yours:

**  **

### **2️⃣ My Educator–AI–Student Boundaries**

> **AI may assist educators by:**
>
> **Students may use AI to:**
>
> **AI must never:**

### **3️⃣ My Teaching Ethics Red Lines**

I pause AI use when:

- 
- 

### **4️⃣ My Teaching Governance Triggers**

I document or escalate when AI affects:

- assessment design

- marking or feedback

- student progression

- curriculum standards

**  **

### **5️⃣ My Reflection & Renewal Practice**

After each delivery cycle, I will:

- review learning evidence

- adjust guidance

- share insights with colleagues

Teaching capability is collective.

## **THE TEACHING COMMITMENT**

> *I design learning intentionally in the presence of AI.  
> I protect student thinking, not just outcomes.  
> I make boundaries explicit and defensible.  
> I govern before I am challenged.  
> I renew teaching through evidence and reflection.*
