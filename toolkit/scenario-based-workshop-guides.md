# Scenario-Based Workshop Guides (Complete Pack)

**Framework:** CloudPedagogy AI Capability Framework (2026 Edition)  
**Licence:** CC BY-NC-SA 4.0  
**Author:** Jonathan Wong

---

## 1. Introduction to the Scenario Pack

The **Scenario-Based Workshop Guides** translate each domain of the CloudPedagogy AI Capability Framework into practical, participatory learning experiences.

Each guide contains:

- a realistic scenario grounded in sector practice  
- clear learning objectives  
- facilitation notes  
- structured activities  
- reflection prompts  
- expected outcomes  

These scenarios can be delivered in workshops, team meetings, institutional retreats, CPD sessions, governance reviews, or curricular design sprints.

They may be run individually (one domain at a time) or combined to explore cross-domain capability.

---

## 2. Domain 1 – AI Awareness and Orientation  
### Scenario: AI-Assisted Tutoring in Higher Education

A university introduces AI-assisted tutoring tools to support student learning. Staff express uncertainty about the accuracy, interpretability, and fairness of the system’s feedback.

### Objectives

- Develop shared understanding of how AI models reason and generate feedback.  
- Identify visible and hidden assumptions embedded in system outputs.  
- Build confidence in communicating system limitations transparently.

### Facilitation Notes

- Provide anonymised or simulated examples of AI-generated feedback.  
- Encourage questioning of data provenance, training samples, and representational gaps.  
- Compare AI-generated advice with human tutor commentary.

### Activities

1. **Bias Mapping**  
   Annotate a system-generated explanation. Identify missing evidence, oversimplifications, or reasoning gaps.

2. **Transparency Ladder**  
   Groups discuss what level of explainability is sufficient for educational use and why.

3. **Ethical Briefing Exercise**  
   Draft a short “AI literacy notice” suitable for inclusion in a course handbook.

### Reflection Questions

- What surprised you about the system’s reasoning process?  
- How can educators communicate limitations responsibly?  
- What literacy skills do staff and students need to engage critically with AI?

### Outcome

Participants gain epistemic awareness and the ability to communicate system limitations clearly and responsibly.

---

## 3. Domain 2 – Human–AI Co-Agency  
### Scenario: AI Triage Assistance in Healthcare

A hospital pilots an AI triage assistant to support rapid clinical decision-making. Clinicians must determine when to rely on the system and when to override it.

### Objectives

- Clarify shared responsibility between clinicians and AI systems.  
- Strengthen human judgement within data-informed workflows.  
- Define ethical boundaries and non-delegable decisions.

### Facilitation Notes

- Provide a realistic anonymised case.  
- Map points where AI input enters the triage workflow.  
- Compare risks of over-reliance versus under-use.

### Activities

1. **Workflow Mapping**  
   Visualise the distribution of tasks between clinicians and AI at each stage.

2. **Oversight Charter**  
   Draft explicit red-line rules defining where human judgement is mandatory.

3. **Ethical Simulation**  
   Role-play a review board examining a misclassification incident.

### Reflection Questions

- When did AI add value, and when did it risk eroding trust?  
- How can documentation strengthen co-agency?  
- What habits preserve situational awareness?

### Outcome

Participants establish practical co-agency boundaries and accountability structures.

---

## 4. Domain 3 – Applied Practice and Innovation  
### Scenario: Climate Adaptation Prototyping in Policy Design

A city authority explores AI models to simulate climate-adaptation strategies. Teams must design transparent prototypes while considering social equity.

### Objectives

- Apply design thinking to create transparent AI prototypes.  
- Evaluate innovations through ethical and equity criteria.  
- Balance creativity with accountability in public-sector experimentation.

### Facilitation Notes

- Provide open climate data and stakeholder profiles.  
- Encourage rapid prototyping and iteration.  
- Pair participants from diverse disciplines and roles.

### Activities

1. **Ideation Sprint**  
   Generate multiple prototypes, then evaluate each using fairness and sustainability criteria.

2. **Stakeholder Canvas**  
   Map which communities benefit or risk exclusion.

3. **Foresight Roundtable**  
   Discuss long-term consequences of proposed decisions.

### Reflection Questions

- What creative possibilities emerged?  
- Which assumptions about fairness were challenged?  
- What downstream effects require governance attention?

### Outcome

Innovation is grounded in ethical inquiry, design thinking, and systemic awareness.

---

## 5. Domain 4 – Ethics, Equity and Impact  
### Scenario: Research Group Using AI for Participant Data Analysis

A multidisciplinary research group employs AI tools to analyse participant datasets. Concerns arise about bias, consent, and interpretability.

### Objectives

- Embed justice, transparency, and accountability in data workflows.  
- Identify ethical risks and propose mitigations.  
- Strengthen communication with participants and oversight bodies.

### Facilitation Notes

- Provide a model ethics-application form.  
- Include dataset samples highlighting representational gaps.  
- Focus on consent, provenance, accessibility, and inclusion.

### Activities

1. **Bias Audit Drill**  
   Review dataset characteristics for demographic bias or omission.

2. **Consent Redesign**  
   Write a participant-friendly explanation of AI processing.

3. **Perspective Exchange**  
   Rotate roles between researcher, participant, and ethics reviewer.

### Reflection Questions

- Whose perspectives were absent from the process?  
- How can ethical design improve the research lifecycle?  
- What supports are needed for ongoing fairness monitoring?

### Outcome

Teams integrate ethical foresight directly into research design and governance.

---

## 6. Domain 5 – Decision-Making and Governance  
### Scenario: AI-Supported Resource Allocation in University Leadership

A university board considers deploying AI to support workload or funding allocation. Members raise concerns about explainability and accountability.

### Objectives

- Identify ethical, operational, and reputational risks.  
- Design oversight structures and decision logs.  
- Strengthen participatory governance.

### Facilitation Notes

- Provide a short governance case (e.g. workload model).  
- Assign roles such as Chair, Ethics Officer, Faculty Lead, Data Scientist.  
- Focus discussion on competing values: efficiency, fairness, transparency.

### Activities

1. **Governance Mapping**  
   Visualise information flow and validation checkpoints.

2. **Risk–Value Matrix**  
   Rank governance priorities (fairness, transparency, accountability).

3. **Audit Trail Simulation**  
   Draft a decision log capturing justification, data use, human sign-off, and review intervals.

### Reflection Questions

- Where must oversight remain non-delegable?  
- What documentation ensures transparency?  
- How can participatory governance build trust?

### Outcome

Participants translate governance principles into operational accountability mechanisms.

---

## 7. Domain 6 – Reflection, Learning and Renewal  
### Scenario: Institutional Review of Multiple AI Pilots

A cross-departmental team reviews several AI pilots to shape an institutional AI strategy.

### Objectives

- Synthesise insights from multiple projects.  
- Identify recurring patterns, risks, and capability gaps.  
- Plan structures for continuous, institution-wide improvement.

### Facilitation Notes

- Collect summaries of past AI pilots (successes, failures, surprises).  
- Use the After-Action Review model: Worked / Surprised / Failed / Next.  
- Focus on system-level learning rather than performance evaluation.

### Activities

1. **Learning Harvest**  
   Group similar insights and identify systemic patterns.

2. **Capability Mapping**  
   Link insights to framework domains to identify maturity levels.

3. **Renewal Charter**  
   Draft a brief institutional statement outlining commitments to learning and adaptation.

### Reflection Questions

- What cross-cutting themes emerged?  
- How can lessons shape future governance and strategic planning?  
- What mechanisms ensure learning becomes visible organisational change?

### Outcome

Reflection becomes an institutional engine for renewal and long-term capability development.

---

## 8. Implementation Guidance

- Scale flexibly — use for 1-hour sessions or full-day retreats.  
- Mix stakeholder roles — encourage cross-disciplinary insight.  
- Document outputs — keep artefacts, mapping exercises, and reflection notes.  
- Re-run scenarios — after 6–12 months to assess capability progression.  
- Link to governance — feed insights into AI policies, ethics reviews, and strategic plans.

---

## Licensing

This resource is released under the **Creative Commons Attribution–NonCommercial–ShareAlike 4.0 International Licence (CC BY-NC-SA 4.0)**.

Please credit:

> **Wong, J. (2026). _CloudPedagogy AI Capability Framework – Scenario-Based Workshop Guides_.**

---

*End of Scenario Pack*  

**CloudPedagogy — AI Capability Framework (2026 Edition)**
